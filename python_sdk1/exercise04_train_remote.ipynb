{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise04 : Train on Remote GPU Virtual Machine\n",
    "\n",
    "Now we run our previous sample (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") on remote virtual machine with GPU utilized.\n",
    "\n",
    "> Note : If you don't have GPU quota, you can also run this example on CPU.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding the following ```%%writefile``` at the beginning of the source code in \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\", this source code is saved as ```./script/train.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train.py\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "# device test\n",
    "print(\"##### List of available GPU #####\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data_folder\",\n",
    "    type=str,\n",
    "    default=\"./data\",\n",
    "    help=\"Folder path for input data\")\n",
    "parser.add_argument(\n",
    "    \"--model_folder\",\n",
    "    type=str,\n",
    "    default=\"./outputs\",  # AML experiments outputs folder\n",
    "    help=\"Folder path for model output\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=\"0.001\",\n",
    "    help=\"Learning Rate\")\n",
    "parser.add_argument(\n",
    "    \"--first_layer\",\n",
    "    type=int,\n",
    "    default=\"128\",\n",
    "    help=\"Neuron number for the first hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--second_layer\",\n",
    "    type=int,\n",
    "    default=\"64\",\n",
    "    help=\"Neuron number for the second hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--epochs_num\",\n",
    "    type=int,\n",
    "    default=\"6\",\n",
    "    help=\"Number of epochs\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# build model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(FLAGS.first_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(FLAGS.second_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(FLAGS.learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# run training\n",
    "train_data_path = os.path.join(FLAGS.data_folder, \"train\")\n",
    "train_data = tf.data.experimental.load(train_data_path)\n",
    "model.fit(\n",
    "    train_data.shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=FLAGS.epochs_num\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_path = os.path.join(FLAGS.model_folder, \"mnist_tf_model\")\n",
    "model.save(model_path)\n",
    "print(\"current working directory : \", os.getcwd())\n",
    "print(\"model folder : \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on remote VM\n",
    "\n",
    "Now let's start to integrate with AML and automate training on remote virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Get workspace setting\n",
    "\n",
    "Before starting, you must read your configuration settings. (See \"[Exercise01 : Prepare Config Settings](./exercise01_prepare_config.ipynb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Create new remote virtual machine\n",
    "\n",
    "Create your new reomte virtual machine with GPU.<br>\n",
    "Before starting, **please check as follows**.\n",
    "\n",
    "- Make sure that the following size (in the following script, ```Standard_NC4as_T4_v3```) is supported in the location (in which AML workspace resides).<br>\n",
    "You can also specify ```location``` in ```provisioning_configuration```, but it's not recommended to set the different location from AML workspace. (Since data in AML workspace will be mounted on this virtual machine.)\n",
    "- You should have quota for ML GPU VM in your Azure subscription. If you don't have, please request quota in Azure Portal.\n",
    "\n",
    "**If you don't have any quota for GPU, please change VM size (such as, Standard_D2_v2).**\n",
    "\n",
    "> Note : If VM already exists, this script will get the existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new.\n",
      "InProgress..\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name='myvm01')\n",
    "    print('found existing:', compute_target.name)\n",
    "except ComputeTargetException:\n",
    "    print('creating new.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC4as_T4_v3', # change such as Standard_NC6 or Standard_D2_v2 if needed\n",
    "        min_nodes=0,\n",
    "        max_nodes=1)\n",
    "    compute_target = ComputeTarget.create(ws, 'myvm01', compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By enabling auto-scaling (from 0 to 1), the node will be terminated if it's inactive. (You can save money.)<br>\n",
    "\n",
    "> Note : You can also attach an existing virtual machine (bring your own compute resource) as a compute target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Get dataset reference for files\n",
    "\n",
    "You can use registered dataset (named ```mnist_dataset```) to mount in your compute target.<br>\n",
    "See \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation.\n",
    "\n",
    "> Note : Dataset registration is not mandatory. (You can mount any data (as dataset) in AML datastore.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "dataset = Dataset.get_by_name(ws, 'mnist_dataset', version='latest')\n",
    "\n",
    "# # For using unregistered data, see below\n",
    "# from azureml.core import Datastore\n",
    "# from azureml.core import Dataset\n",
    "# ds = ws.get_default_datastore()\n",
    "# ds_paths = [(ds, 'tfdata/')]\n",
    "# dataset = Dataset.File.from_files(path = ds_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Run script and wait for completion\n",
    "\n",
    "Submit a training job.\n",
    "\n",
    "In this example, I use the registered dataset named ```mnist_dataset``` and mount this data in my compute target. (Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation.)\n",
    "\n",
    "> Note : Here I use AML built-in environment (```AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu```), but you can build and use your own environment.<br>\n",
    "> In the later example in this notebook, I'll run the same script with my own environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: tf_remote_experiment_1664945818_1d396756\n",
      "Web View: https://ml.azure.com/runs/tf_remote_experiment_1664945818_1d396756?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n",
      "Streaming user_logs/std_log.txt\n",
      "===============================\n",
      "\n",
      "##### List of available GPU #####\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2022-10-05 05:05:07.148158: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 05:05:07.816872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10792 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 4dd9:00:00.0, compute capability: 3.7\n",
      "Epoch 1/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 5:54 - loss: 85.2067 - sparse_categorical_accuracy: 0.11\n",
      " 25/469 [>.............................] - ETA: 0s - loss: 18.2261 - sparse_categorical_accuracy: 0.5256\n",
      " 48/469 [==>...........................] - ETA: 0s - loss: 11.4248 - sparse_categorical_accuracy: 0.63\n",
      " 70/469 [===>..........................] - ETA: 0s - loss: 8.7134 - sparse_categorical_accuracy: 0.6878\n",
      " 94/469 [=====>........................] - ETA: 0s - loss: 7.0782 - sparse_categorical_accuracy: 0.720\n",
      "120/469 [======>.......................] - ETA: 0s - loss: 6.0041 - sparse_categorical_accuracy: 0.736\n",
      "144/469 [========>.....................] - ETA: 0s - loss: 5.2469 - sparse_categorical_accuracy: 0.744\n",
      "168/469 [=========>....................] - ETA: 0s - loss: 4.6691 - sparse_categorical_accuracy: 0.753\n",
      "190/469 [===========>..................] - ETA: 0s - loss: 4.2499 - sparse_categorical_accuracy: 0.759\n",
      "212/469 [============>.................] - ETA: 0s - loss: 3.9065 - sparse_categorical_accuracy: 0.766\n",
      "235/469 [==============>...............] - ETA: 0s - loss: 3.6140 - sparse_categorical_accuracy: 0.772\n",
      "257/469 [===============>..............] - ETA: 0s - loss: 3.3787 - sparse_categorical_accuracy: 0.776\n",
      "280/469 [================>.............] - ETA: 0s - loss: 3.1635 - sparse_categorical_accuracy: 0.782\n",
      "302/469 [==================>...........] - ETA: 0s - loss: 2.9899 - sparse_categorical_accuracy: 0.785\n",
      "324/469 [===================>..........] - ETA: 0s - loss: 2.8358 - sparse_categorical_accuracy: 0.789\n",
      "347/469 [=====================>........] - ETA: 0s - loss: 2.6933 - sparse_categorical_accuracy: 0.793\n",
      "368/469 [======================>.......] - ETA: 0s - loss: 2.5755 - sparse_categorical_accuracy: 0.796\n",
      "390/469 [=======================>......] - ETA: 0s - loss: 2.4684 - sparse_categorical_accuracy: 0.799\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 2.3670 - sparse_categorical_accuracy: 0.802\n",
      "436/469 [==========================>...] - ETA: 0s - loss: 2.2700 - sparse_categorical_accuracy: 0.806\n",
      "458/469 [============================>.] - ETA: 0s - loss: 2.1823 - sparse_categorical_accuracy: 0.811\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 2.1421 - sparse_categorical_accuracy: 0.8132\n",
      "Epoch 2/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 16s - loss: 0.3339 - sparse_categorical_accuracy: 0.89\n",
      " 24/469 [>.............................] - ETA: 0s - loss: 0.4805 - sparse_categorical_accuracy: 0.8890\n",
      " 45/469 [=>............................] - ETA: 0s - loss: 0.4572 - sparse_categorical_accuracy: 0.892\n",
      " 67/469 [===>..........................] - ETA: 0s - loss: 0.4741 - sparse_categorical_accuracy: 0.886\n",
      " 85/469 [====>.........................] - ETA: 0s - loss: 0.4670 - sparse_categorical_accuracy: 0.883\n",
      "109/469 [=====>........................] - ETA: 0s - loss: 0.4591 - sparse_categorical_accuracy: 0.885\n",
      "132/469 [=======>......................] - ETA: 0s - loss: 0.4670 - sparse_categorical_accuracy: 0.884\n",
      "156/469 [========>.....................] - ETA: 0s - loss: 0.4528 - sparse_categorical_accuracy: 0.888\n",
      "181/469 [==========>...................] - ETA: 0s - loss: 0.4472 - sparse_categorical_accuracy: 0.888\n",
      "203/469 [===========>..................] - ETA: 0s - loss: 0.4423 - sparse_categorical_accuracy: 0.890\n",
      "227/469 [=============>................] - ETA: 0s - loss: 0.4404 - sparse_categorical_accuracy: 0.891\n",
      "251/469 [===============>..............] - ETA: 0s - loss: 0.4402 - sparse_categorical_accuracy: 0.891\n",
      "275/469 [================>.............] - ETA: 0s - loss: 0.4328 - sparse_categorical_accuracy: 0.893\n",
      "298/469 [==================>...........] - ETA: 0s - loss: 0.4302 - sparse_categorical_accuracy: 0.894\n",
      "322/469 [===================>..........] - ETA: 0s - loss: 0.4243 - sparse_categorical_accuracy: 0.895\n",
      "345/469 [=====================>........] - ETA: 0s - loss: 0.4229 - sparse_categorical_accuracy: 0.894\n",
      "370/469 [======================>.......] - ETA: 0s - loss: 0.4168 - sparse_categorical_accuracy: 0.895\n",
      "393/469 [========================>.....] - ETA: 0s - loss: 0.4142 - sparse_categorical_accuracy: 0.895\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 0.4115 - sparse_categorical_accuracy: 0.896\n",
      "439/469 [===========================>..] - ETA: 0s - loss: 0.4056 - sparse_categorical_accuracy: 0.898\n",
      "461/469 [============================>.] - ETA: 0s - loss: 0.3977 - sparse_categorical_accuracy: 0.900\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3968 - sparse_categorical_accuracy: 0.9007\n",
      "Epoch 3/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 15s - loss: 0.4129 - sparse_categorical_accuracy: 0.92\n",
      " 27/469 [>.............................] - ETA: 0s - loss: 0.3005 - sparse_categorical_accuracy: 0.9242\n",
      " 53/469 [==>...........................] - ETA: 0s - loss: 0.2865 - sparse_categorical_accuracy: 0.925\n",
      " 71/469 [===>..........................] - ETA: 0s - loss: 0.2998 - sparse_categorical_accuracy: 0.922\n",
      " 95/469 [=====>........................] - ETA: 0s - loss: 0.2975 - sparse_categorical_accuracy: 0.921\n",
      "119/469 [======>.......................] - ETA: 0s - loss: 0.2907 - sparse_categorical_accuracy: 0.924\n",
      "143/469 [========>.....................] - ETA: 0s - loss: 0.2966 - sparse_categorical_accuracy: 0.923\n",
      "168/469 [=========>....................] - ETA: 0s - loss: 0.2947 - sparse_categorical_accuracy: 0.924\n",
      "191/469 [===========>..................] - ETA: 0s - loss: 0.2902 - sparse_categorical_accuracy: 0.924\n",
      "216/469 [============>.................] - ETA: 0s - loss: 0.2895 - sparse_categorical_accuracy: 0.925\n",
      "239/469 [==============>...............] - ETA: 0s - loss: 0.2851 - sparse_categorical_accuracy: 0.926\n",
      "264/469 [===============>..............] - ETA: 0s - loss: 0.2850 - sparse_categorical_accuracy: 0.926\n",
      "288/469 [=================>............] - ETA: 0s - loss: 0.2854 - sparse_categorical_accuracy: 0.927\n",
      "312/469 [==================>...........] - ETA: 0s - loss: 0.2814 - sparse_categorical_accuracy: 0.927\n",
      "338/469 [====================>.........] - ETA: 0s - loss: 0.2819 - sparse_categorical_accuracy: 0.926\n",
      "363/469 [======================>.......] - ETA: 0s - loss: 0.2804 - sparse_categorical_accuracy: 0.926\n",
      "386/469 [=======================>......] - ETA: 0s - loss: 0.2793 - sparse_categorical_accuracy: 0.926\n",
      "409/469 [=========================>....] - ETA: 0s - loss: 0.2809 - sparse_categorical_accuracy: 0.926\n",
      "434/469 [==========================>...] - ETA: 0s - loss: 0.2795 - sparse_categorical_accuracy: 0.926\n",
      "456/469 [============================>.] - ETA: 0s - loss: 0.2743 - sparse_categorical_accuracy: 0.927\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2719 - sparse_categorical_accuracy: 0.9287\n",
      "Epoch 4/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 15s - loss: 0.2350 - sparse_categorical_accuracy: 0.92\n",
      " 26/469 [>.............................] - ETA: 0s - loss: 0.2488 - sparse_categorical_accuracy: 0.9387\n",
      " 51/469 [==>...........................] - ETA: 0s - loss: 0.2281 - sparse_categorical_accuracy: 0.941\n",
      " 75/469 [===>..........................] - ETA: 0s - loss: 0.2374 - sparse_categorical_accuracy: 0.938\n",
      " 98/469 [=====>........................] - ETA: 0s - loss: 0.2352 - sparse_categorical_accuracy: 0.938\n",
      "122/469 [======>.......................] - ETA: 0s - loss: 0.2370 - sparse_categorical_accuracy: 0.938\n",
      "145/469 [========>.....................] - ETA: 0s - loss: 0.2346 - sparse_categorical_accuracy: 0.938\n",
      "168/469 [=========>....................] - ETA: 0s - loss: 0.2269 - sparse_categorical_accuracy: 0.940\n",
      "192/469 [===========>..................] - ETA: 0s - loss: 0.2240 - sparse_categorical_accuracy: 0.940\n",
      "215/469 [============>.................] - ETA: 0s - loss: 0.2233 - sparse_categorical_accuracy: 0.941\n",
      "239/469 [==============>...............] - ETA: 0s - loss: 0.2201 - sparse_categorical_accuracy: 0.941\n",
      "265/469 [===============>..............] - ETA: 0s - loss: 0.2187 - sparse_categorical_accuracy: 0.941\n",
      "286/469 [=================>............] - ETA: 0s - loss: 0.2154 - sparse_categorical_accuracy: 0.942\n",
      "308/469 [==================>...........] - ETA: 0s - loss: 0.2146 - sparse_categorical_accuracy: 0.942\n",
      "332/469 [====================>.........] - ETA: 0s - loss: 0.2146 - sparse_categorical_accuracy: 0.942\n",
      "355/469 [=====================>........] - ETA: 0s - loss: 0.2128 - sparse_categorical_accuracy: 0.943\n",
      "379/469 [=======================>......] - ETA: 0s - loss: 0.2107 - sparse_categorical_accuracy: 0.943\n",
      "402/469 [========================>.....] - ETA: 0s - loss: 0.2097 - sparse_categorical_accuracy: 0.943\n",
      "426/469 [==========================>...] - ETA: 0s - loss: 0.2113 - sparse_categorical_accuracy: 0.943\n",
      "447/469 [===========================>..] - ETA: 0s - loss: 0.2093 - sparse_categorical_accuracy: 0.943\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2053 - sparse_categorical_accuracy: 0.9446\n",
      "Epoch 5/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 17s - loss: 0.0869 - sparse_categorical_accuracy: 0.96\n",
      " 26/469 [>.............................] - ETA: 0s - loss: 0.1670 - sparse_categorical_accuracy: 0.9534\n",
      " 43/469 [=>............................] - ETA: 1s - loss: 0.1588 - sparse_categorical_accuracy: 0.956\n",
      " 65/469 [===>..........................] - ETA: 0s - loss: 0.1692 - sparse_categorical_accuracy: 0.953\n",
      " 88/469 [====>.........................] - ETA: 0s - loss: 0.1708 - sparse_categorical_accuracy: 0.952\n",
      "112/469 [======>.......................] - ETA: 0s - loss: 0.1760 - sparse_categorical_accuracy: 0.951\n",
      "136/469 [=======>......................] - ETA: 0s - loss: 0.1761 - sparse_categorical_accuracy: 0.950\n",
      "160/469 [=========>....................] - ETA: 0s - loss: 0.1758 - sparse_categorical_accuracy: 0.950\n",
      "184/469 [==========>...................] - ETA: 0s - loss: 0.1729 - sparse_categorical_accuracy: 0.951\n",
      "208/469 [============>.................] - ETA: 0s - loss: 0.1717 - sparse_categorical_accuracy: 0.952\n",
      "230/469 [=============>................] - ETA: 0s - loss: 0.1713 - sparse_categorical_accuracy: 0.951\n",
      "255/469 [===============>..............] - ETA: 0s - loss: 0.1709 - sparse_categorical_accuracy: 0.951\n",
      "280/469 [================>.............] - ETA: 0s - loss: 0.1684 - sparse_categorical_accuracy: 0.952\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 0.1702 - sparse_categorical_accuracy: 0.952\n",
      "325/469 [===================>..........] - ETA: 0s - loss: 0.1710 - sparse_categorical_accuracy: 0.952\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.1719 - sparse_categorical_accuracy: 0.951\n",
      "358/469 [=====================>........] - ETA: 0s - loss: 0.1715 - sparse_categorical_accuracy: 0.951\n",
      "383/469 [=======================>......] - ETA: 0s - loss: 0.1711 - sparse_categorical_accuracy: 0.951\n",
      "406/469 [========================>.....] - ETA: 0s - loss: 0.1713 - sparse_categorical_accuracy: 0.951\n",
      "430/469 [==========================>...] - ETA: 0s - loss: 0.1714 - sparse_categorical_accuracy: 0.951\n",
      "452/469 [===========================>..] - ETA: 0s - loss: 0.1691 - sparse_categorical_accuracy: 0.952\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1671 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 6/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 16s - loss: 0.2739 - sparse_categorical_accuracy: 0.92\n",
      " 25/469 [>.............................] - ETA: 0s - loss: 0.1387 - sparse_categorical_accuracy: 0.9584\n",
      " 51/469 [==>...........................] - ETA: 0s - loss: 0.1411 - sparse_categorical_accuracy: 0.959\n",
      " 76/469 [===>..........................] - ETA: 0s - loss: 0.1578 - sparse_categorical_accuracy: 0.956\n",
      " 97/469 [=====>........................] - ETA: 0s - loss: 0.1582 - sparse_categorical_accuracy: 0.956\n",
      "120/469 [======>.......................] - ETA: 0s - loss: 0.1544 - sparse_categorical_accuracy: 0.956\n",
      "144/469 [========>.....................] - ETA: 0s - loss: 0.1538 - sparse_categorical_accuracy: 0.957\n",
      "167/469 [=========>....................] - ETA: 0s - loss: 0.1530 - sparse_categorical_accuracy: 0.957\n",
      "190/469 [===========>..................] - ETA: 0s - loss: 0.1530 - sparse_categorical_accuracy: 0.957\n",
      "214/469 [============>.................] - ETA: 0s - loss: 0.1531 - sparse_categorical_accuracy: 0.957\n",
      "238/469 [==============>...............] - ETA: 0s - loss: 0.1522 - sparse_categorical_accuracy: 0.957\n",
      "261/469 [===============>..............] - ETA: 0s - loss: 0.1515 - sparse_categorical_accuracy: 0.957\n",
      "283/469 [=================>............] - ETA: 0s - loss: 0.1497 - sparse_categorical_accuracy: 0.958\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 0.1525 - sparse_categorical_accuracy: 0.957\n",
      "325/469 [===================>..........] - ETA: 0s - loss: 0.1512 - sparse_categorical_accuracy: 0.957\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 0.1511 - sparse_categorical_accuracy: 0.958\n",
      "366/469 [======================>.......] - ETA: 0s - loss: 0.1509 - sparse_categorical_accuracy: 0.958\n",
      "389/469 [=======================>......] - ETA: 0s - loss: 0.1507 - sparse_categorical_accuracy: 0.958\n",
      "412/469 [=========================>....] - ETA: 0s - loss: 0.1514 - sparse_categorical_accuracy: 0.957\n",
      "437/469 [==========================>...] - ETA: 0s - loss: 0.1515 - sparse_categorical_accuracy: 0.958\n",
      "461/469 [============================>.] - ETA: 0s - loss: 0.1487 - sparse_categorical_accuracy: 0.958\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9590\n",
      "2022-10-05 05:05:15.490027: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "current working directory :  /mnt/azureml/cr/j/56aeee3146ec4619922930eb00ef9a8c/exe/wd\n",
      "model folder :  ./outputs/mnist_tf_model\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.06276679039001465 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: tf_remote_experiment_1664945818_1d396756\n",
      "Web View: https://ml.azure.com/runs/tf_remote_experiment_1664945818_1d396756?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'tf_remote_experiment_1664945818_1d396756',\n",
       " 'target': 'myvm01',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-10-05T05:02:32.009974Z',\n",
       " 'endTimeUtc': '2022-10-05T05:05:20.568375Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n",
       "  'ContentSnapshotId': 'd1e62fa9-0a70-4726-be39-2b23edcbacab',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '16c18986-c760-49b0-a222-eeb89a5f9262'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__16c18986', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data_folder', 'DatasetConsumptionConfig:input__16c18986'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'myvm01',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__16c18986': {'dataLocation': {'dataset': {'id': '16c18986-c760-49b0-a222-eeb89a5f9262',\n",
       "      'name': 'mnist_dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None,\n",
       "     'type': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__16c18986',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu',\n",
       "   'version': '23',\n",
       "   'assetId': 'azureml://registries/azureml/environments/AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu/versions/23',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': None,\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': None,\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': \"FROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:20220902.v1\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/tensorflow-2.7\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.8 pip=20.2.4\\n\\n# Prepend path to AzureML conda environment\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\n# Install pip dependencies\\nRUN HOROVOD_WITH_TENSORFLOW=1 pip install 'matplotlib~=3.5.0' \\\\\\n                                          'psutil~=5.8.0' \\\\\\n                                          'tqdm~=4.62.0' \\\\\\n                                          'pandas~=1.3.0' \\\\\\n                                          'scipy~=1.7.0' \\\\\\n                                          'numpy~=1.21.0' \\\\\\n                                          'ipykernel~=6.0' \\\\\\n                                          'azureml-core==1.45.0' \\\\\\n                                          'azureml-defaults==1.45.0' \\\\\\n                                          'azureml-mlflow==1.45.0' \\\\\\n                                          'azureml-telemetry==1.45.0' \\\\\\n                                          'tensorboard~=2.7.0' \\\\\\n                                          'tensorflow-gpu~=2.7.0' \\\\\\n                                          'tensorflow-datasets~=4.5.0' \\\\\\n                                          'onnxruntime-gpu~=1.9.0' \\\\\\n                                          'protobuf~=3.20' \\\\\\n                                          'horovod[tensorflow-gpu]~=0.23.0'\\n                          \\n# This is needed for mpi to locate libpython\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\",\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'user_logs/std_log.txt': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=azLLxpK2UCUuozkLF1jL%2B7ptP5fJAnLqfq5IIeOOWQ4%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A11Z&se=2022-10-05T13%3A06%3A11Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=DW2IJ2RY5bOTfzB5%2BNL7z0Kua%2ByuP71Hn4SagNoRIOM%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/data_capability/data-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=F8hjxGJ4mbwD79iw849Dbntq0yX2xkg6DKWV7xcK1fk%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/data_capability/rslex.log.2022-10-05-05': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/data_capability/rslex.log.2022-10-05-05?sv=2019-07-07&sr=b&sig=3sDkY1EgiIgeXmGTXWwvRvQRyXSmAQxwVbJ83XEG2Fc%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=4ghUePdjp%2Bj3qqQl%2B3vS81smIqqrjOZ%2FoRo3Fic05N0%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=1I6urm%2FpEnykJLKl3g6xJshuC1sos3Z7Y96yu95efWg%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=97NK%2BK%2F7lGo096mAwUxzfSfggxFlqmA58wAk6%2FX2Q5A%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=10jtqxkfwvPHQO9No%2FoA0Yud4ywouV6fUD6PRsj7l%2FU%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664945818_1d396756/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=G3flSvWSrdY3dZbBuD%2FrTMjLJlUhYAYzqRpT%2FmfOzDQ%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T04%3A56%3A12Z&se=2022-10-05T13%3A06%3A12Z&sp=r'},\n",
       " 'submittedBy': 'Tsuyoshi Matsuzaki'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, Environment, Run, ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "# create script run config\n",
    "tf_env = Environment.get(workspace=ws, name='AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu')\n",
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='train.py',\n",
    "    arguments=['--data_folder', dataset.as_mount()],\n",
    "    compute_target=compute_target,\n",
    "    environment=tf_env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True))\n",
    "\n",
    "# submit and run !\n",
    "exp = Experiment(workspace=ws, name='tf_remote_experiment')\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Download results and evaluate\n",
    "\n",
    "Now let's check the generated model in local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check generated files and logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/mnist_tf_model/keras_metadata.pb',\n",
       " 'outputs/mnist_tf_model/saved_model.pb',\n",
       " 'outputs/mnist_tf_model/variables/variables.data-00000-of-00001',\n",
       " 'outputs/mnist_tf_model/variables/variables.index',\n",
       " 'system_logs/cs_capability/cs-capability.log',\n",
       " 'system_logs/data_capability/data-capability.log',\n",
       " 'system_logs/data_capability/rslex.log.2022-10-05-05',\n",
       " 'system_logs/hosttools_capability/hosttools-capability.log',\n",
       " 'system_logs/lifecycler/execution-wrapper.log',\n",
       " 'system_logs/lifecycler/lifecycler.log',\n",
       " 'system_logs/metrics_capability/metrics-capability.log',\n",
       " 'system_logs/snapshot_capability/snapshot-capability.log',\n",
       " 'user_logs/std_log.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download model into your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file(\n",
    "    name='outputs/mnist_tf_model/keras_metadata.pb',\n",
    "    output_file_path='remote_model/keras_metadata.pb')\n",
    "run.download_file(\n",
    "    name='outputs/mnist_tf_model/saved_model.pb',\n",
    "    output_file_path='remote_model/saved_model.pb')\n",
    "run.download_file(\n",
    "    name='outputs/mnist_tf_model/variables/variables.data-00000-of-00001',\n",
    "    output_file_path='remote_model/variables/variables.data-00000-of-00001')\n",
    "run.download_file(\n",
    "    name='outputs/mnist_tf_model/variables/variables.index',\n",
    "    output_file_path='remote_model/variables/variables.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict your test data using downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 05:11:26.239294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 05:11:26.393022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-05 05:11:26.393059: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-05 05:11:26.425198: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-05 05:11:27.169895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-05 05:11:27.170003: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-05 05:11:27.170015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-05 05:11:27.816541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-05 05:11:27.816580: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-05 05:11:27.816612: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (client1005): /proc/driver/nvidia/version does not exist\n",
      "2022-10-05 05:11:27.816836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 7, True 7\n",
      "Predicted 2, True 2\n",
      "Predicted 1, True 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test_data = tf.data.Dataset.load(\"./data/test\")\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"./remote_model\")\n",
    "for image, true_value in test_data.take(3):\n",
    "    pred_output = loaded_model(tf.expand_dims(image, axis=0))\n",
    "    pred_value = tf.math.argmax(pred_output, axis=-1).numpy().item()\n",
    "    print(\"Predicted {}, True {}\".format(pred_value, true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Register Model with Dataset reference\n",
    "\n",
    "By registering model with dataset reference, you can trace the model with the corresponding dataset version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(\n",
    "    model_name='mnist_model_test',\n",
    "    model_path='outputs/mnist_tf_model',\n",
    "    datasets =[('training data',dataset)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to track data used in this model, see this model in [Azure Machine Learning Studio](https://ml.azure.com/) and select \"Data\" tab. (See the following screenshot.)\n",
    "\n",
    "![data tracking](https://tsmatz.files.wordpress.com/2021/08/20210823_track_data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Step 7 : Train with your own environment\n",
    "\n",
    "**This is not mandatory. (You can skip this section.)**\n",
    "\n",
    "You can also build your own environment with custom docker image.<br>\n",
    "Here we create a new docker environments for running scripts, and run the same training with this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register custom environment (named ```test-remote-gpu-env```) in AML with the following conda configuration.<br>\n",
    "Here I use ```DEFAULT_GPU_IMAGE``` (```mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04```), but you can also bring your own image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"assetId\": \"azureml://locations/eastus/workspaces/9f284df9-d636-40ed-bae1-0303c21d4b4f/environments/test-remote-gpu-env/versions/3\",\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"buildContext\": null,\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"test-remote-gpu-env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"tensorflow-gpu==2.10.0\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"3\"\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# create environment\n",
    "env = Environment('test-remote-gpu-env')\n",
    "env.python.conda_dependencies = CondaDependencies.create(\n",
    "    python_version=\"3.8\",\n",
    "    pip_packages=['tensorflow-gpu==2.10.0'])\n",
    "env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04'\n",
    "# You can also use default GPU image (azureml.core.runconfig.DEFAULT_GPU_IMAGE)\n",
    "\n",
    "# register environment to re-use later\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train script with above custom environment.\n",
    "\n",
    "It will take a long time (over 30 minutes) for the first time run, because it'll pull base image, generate new image (custom environment), start nodes in cluster, and run scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: tf_remote_experiment_1664949349_0c9b7841\n",
      "Web View: https://ml.azure.com/runs/tf_remote_experiment_1664949349_0c9b7841?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2022/10/05 05:55:52 Downloading source code...\n",
      "2022/10/05 05:55:53 Finished downloading source code\n",
      "2022/10/05 05:55:54 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2022/10/05 05:55:54 Successfully set up Docker network: acb_default_network\n",
      "2022/10/05 05:55:54 Setting up Docker configuration...\n",
      "2022/10/05 05:55:55 Successfully set up Docker configuration\n",
      "2022/10/05 05:55:55 Logging in to registry: 9f284df9d63640edbae10303c21d4b4f.azurecr.io\n",
      "2022/10/05 05:55:56 Successfully logged into 9f284df9d63640edbae10303c21d4b4f.azurecr.io\n",
      "2022/10/05 05:55:56 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/10/05 05:55:56 Scanning for dependencies...\n",
      "2022/10/05 05:55:56 Successfully scanned dependencies\n",
      "2022/10/05 05:55:56 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04@sha256:67c2d44ef91b157d07646d9fd3e28cb1f66ea3012b4b47b5dcc809a1285d6b19\n",
      "mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04@sha256:67c2d44ef91b157d07646d9fd3e28cb1f66ea3012b4b47b5dcc809a1285d6b19: Pulling from azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04\n",
      "d7bfe07ed847: Already exists\n",
      "bbbbd451a669: Pulling fs layer\n",
      "773163705c35: Pulling fs layer\n",
      "d6949fcf1aef: Pulling fs layer\n",
      "3eb73064088b: Pulling fs layer\n",
      "5ac77df56003: Pulling fs layer\n",
      "5bfbf9695de0: Pulling fs layer\n",
      "ea86fb2cde3e: Pulling fs layer\n",
      "25efcd6bf627: Pulling fs layer\n",
      "5541c4177577: Pulling fs layer\n",
      "5803229e2e9b: Pulling fs layer\n",
      "2d090843b138: Pulling fs layer\n",
      "380ddf01c063: Pulling fs layer\n",
      "4d26826b73d7: Pulling fs layer\n",
      "5b7f19070c53: Pulling fs layer\n",
      "d1670d71cc75: Pulling fs layer\n",
      "9c1f879b34c4: Pulling fs layer\n",
      "78cc86e7aa36: Pulling fs layer\n",
      "dfa6b1019a33: Pulling fs layer\n",
      "52db90e9a18b: Pulling fs layer\n",
      "fbb179b41f19: Pulling fs layer\n",
      "1e28a987fdd2: Pulling fs layer\n",
      "3569a6636f71: Pulling fs layer\n",
      "3eb73064088b: Waiting\n",
      "5ac77df56003: Waiting\n",
      "5bfbf9695de0: Waiting\n",
      "ea86fb2cde3e: Waiting\n",
      "25efcd6bf627: Waiting\n",
      "5541c4177577: Waiting\n",
      "5803229e2e9b: Waiting\n",
      "2d090843b138: Waiting\n",
      "380ddf01c063: Waiting\n",
      "4d26826b73d7: Waiting\n",
      "5b7f19070c53: Waiting\n",
      "d1670d71cc75: Waiting\n",
      "9c1f879b34c4: Waiting\n",
      "78cc86e7aa36: Waiting\n",
      "dfa6b1019a33: Waiting\n",
      "52db90e9a18b: Waiting\n",
      "fbb179b41f19: Waiting\n",
      "1e28a987fdd2: Waiting\n",
      "3569a6636f71: Waiting\n",
      "d6949fcf1aef: Verifying Checksum\n",
      "d6949fcf1aef: Download complete\n",
      "bbbbd451a669: Verifying Checksum\n",
      "bbbbd451a669: Download complete\n",
      "773163705c35: Verifying Checksum\n",
      "773163705c35: Download complete\n",
      "3eb73064088b: Verifying Checksum\n",
      "3eb73064088b: Download complete\n",
      "5bfbf9695de0: Verifying Checksum\n",
      "5bfbf9695de0: Download complete\n",
      "25efcd6bf627: Verifying Checksum\n",
      "25efcd6bf627: Download complete\n",
      "bbbbd451a669: Pull complete\n",
      "773163705c35: Pull complete\n",
      "d6949fcf1aef: Pull complete\n",
      "3eb73064088b: Pull complete\n",
      "5ac77df56003: Verifying Checksum\n",
      "5ac77df56003: Download complete\n",
      "ea86fb2cde3e: Verifying Checksum\n",
      "ea86fb2cde3e: Download complete\n",
      "2d090843b138: Verifying Checksum\n",
      "2d090843b138: Download complete\n",
      "380ddf01c063: Verifying Checksum\n",
      "380ddf01c063: Download complete\n",
      "4d26826b73d7: Verifying Checksum\n",
      "4d26826b73d7: Download complete\n",
      "5541c4177577: Verifying Checksum\n",
      "5541c4177577: Download complete\n",
      "5b7f19070c53: Verifying Checksum\n",
      "5b7f19070c53: Download complete\n",
      "d1670d71cc75: Verifying Checksum\n",
      "d1670d71cc75: Download complete\n",
      "9c1f879b34c4: Verifying Checksum\n",
      "9c1f879b34c4: Download complete\n",
      "78cc86e7aa36: Verifying Checksum\n",
      "78cc86e7aa36: Download complete\n",
      "dfa6b1019a33: Verifying Checksum\n",
      "dfa6b1019a33: Download complete\n",
      "fbb179b41f19: Verifying Checksum\n",
      "fbb179b41f19: Download complete\n",
      "52db90e9a18b: Verifying Checksum\n",
      "52db90e9a18b: Download complete\n",
      "3569a6636f71: Verifying Checksum\n",
      "3569a6636f71: Download complete\n",
      "1e28a987fdd2: Verifying Checksum\n",
      "1e28a987fdd2: Download complete\n",
      "5803229e2e9b: Verifying Checksum\n",
      "5803229e2e9b: Download complete\n",
      "5ac77df56003: Pull complete\n",
      "5bfbf9695de0: Pull complete\n",
      "\n",
      "ea86fb2cde3e: Pull complete\n",
      "25efcd6bf627: Pull complete\n",
      "\n",
      "5541c4177577: Pull complete\n",
      "5803229e2e9b: Pull complete\n",
      "2d090843b138: Pull complete\n",
      "380ddf01c063: Pull complete\n",
      "4d26826b73d7: Pull complete\n",
      "5b7f19070c53: Pull complete\n",
      "d1670d71cc75: Pull complete\n",
      "9c1f879b34c4: Pull complete\n",
      "78cc86e7aa36: Pull complete\n",
      "dfa6b1019a33: Pull complete\n",
      "52db90e9a18b: Pull complete\n",
      "fbb179b41f19: Pull complete\n",
      "1e28a987fdd2: Pull complete\n",
      "3569a6636f71: Pull complete\n",
      "Digest: sha256:67c2d44ef91b157d07646d9fd3e28cb1f66ea3012b4b47b5dcc809a1285d6b19\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04@sha256:67c2d44ef91b157d07646d9fd3e28cb1f66ea3012b4b47b5dcc809a1285d6b19\n",
      " ---> e118e46c6fa2\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 637f28920eb9\n",
      "Removing intermediate container 637f28920eb9\n",
      " ---> c4548bbfb841\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 97508e094240\n",
      "Removing intermediate container 97508e094240\n",
      " ---> 57066ee826de\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in f4d0b8cea1ca\n",
      "Removing intermediate container f4d0b8cea1ca\n",
      " ---> 6400f2b72d79\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> fce05240c0e8\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in ab703b3eb04d\n",
      "Removing intermediate container ab703b3eb04d\n",
      " ---> 1c9e55637165\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> ce166297d6bd\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in a7441c134696\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "zlib-1.2.12          | 130 KB    |            |   0% \n",
      "zlib-1.2.12          | 130 KB    | ########## | 100% \n",
      "\n",
      "ld_impl_linux-64-2.3 | 732 KB    |            |   0% \n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \n",
      "ld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \n",
      "\n",
      "setuptools-61.2.0    | 1.3 MB    |            |   0% \n",
      "setuptools-61.2.0    | 1.3 MB    | ########## | 100% \n",
      "setuptools-61.2.0    | 1.3 MB    | ########## | 100% \n",
      "\n",
      "readline-8.1.2       | 423 KB    |            |   0% \n",
      "readline-8.1.2       | 423 KB    | ########## | 100% \n",
      "readline-8.1.2       | 423 KB    | ########## | 100% \n",
      "\n",
      "wheel-0.37.1         | 31 KB     |            |   0% \n",
      "wheel-0.37.1         | 31 KB     | ########## | 100% \n",
      "\n",
      "ncurses-6.3          | 1.1 MB    |            |   0% \n",
      "ncurses-6.3          | 1.1 MB    | ########## | 100% \n",
      "ncurses-6.3          | 1.1 MB    | ########## | 100% \n",
      "\n",
      "python-3.8.13        | 22.7 MB   |            |   0% \n",
      "python-3.8.13        | 22.7 MB   | ####2      |  42% \n",
      "python-3.8.13        | 22.7 MB   | ########## | 100% \n",
      "python-3.8.13        | 22.7 MB   | ########## | 100% \n",
      "\n",
      "libffi-3.3           | 54 KB     |            |   0% \n",
      "libffi-3.3           | 54 KB     | ########## | 100% \n",
      "\n",
      "_libgcc_mutex-0.1    | 3 KB      |            |   0% \n",
      "_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n",
      "\n",
      "libgomp-11.2.0       | 560 KB    |            |   0% \n",
      "libgomp-11.2.0       | 560 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    |            |   0% \n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \n",
      "libstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \n",
      "\n",
      "sqlite-3.39.2        | 1.5 MB    |            |   0% \n",
      "sqlite-3.39.2        | 1.5 MB    | ########## | 100% \n",
      "sqlite-3.39.2        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "_openmp_mutex-5.1    | 20 KB     |            |   0% \n",
      "_openmp_mutex-5.1    | 20 KB     | ########## | 100% \n",
      "\n",
      "certifi-2022.6.15    | 156 KB    |            |   0% \n",
      "certifi-2022.6.15    | 156 KB    | ########## | 100% \n",
      "\n",
      "pip-22.1.2           | 2.9 MB    |            |   0% \n",
      "pip-22.1.2           | 2.9 MB    | ########## | 100% \n",
      "pip-22.1.2           | 2.9 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1q       | 3.8 MB    |            |   0% \n",
      "openssl-1.1.1q       | 3.8 MB    | ########## | 100% \n",
      "openssl-1.1.1q       | 3.8 MB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 389 KB    |            |   0% \n",
      "xz-5.2.5             | 389 KB    | ########## | 100% \n",
      "xz-5.2.5             | 389 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2022 | 131 KB    |            |   0% \n",
      "ca-certificates-2022 | 131 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.12            | 3.3 MB    |            |   0% \n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \n",
      "tk-8.6.12            | 3.3 MB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-11.2.0     | 8.5 MB    |            |   0% \n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \n",
      "libgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.pnaldeb1.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting tensorflow-gpu==2.10.0\n",
      "  Downloading tensorflow_gpu-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "      578.1/578.1 MB 5.0 MB/s eta 0:00:00\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "      1.7/1.7 MB 98.7 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.49.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "      4.7/4.7 MB 124.9 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "      65.5/65.5 kB 17.2 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "      81.0/81.0 kB 19.1 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.23.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "      17.1/17.1 MB 86.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/lib/python3.8/site-packages (from tensorflow-gpu==2.10.0->-r /azureml-environment-setup/condaenv.pnaldeb1.requirements.txt (line 1)) (61.2.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "      5.9/5.9 MB 109.0 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "      4.5/4.5 MB 137.0 MB/s eta 0:00:00\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "      42.6/42.6 kB 9.2 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "      2.4/2.4 MB 124.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "      438.7/438.7 kB 72.7 MB/s eta 0:00:00\n",
      "Collecting packaging\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "      40.8/40.8 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "      57.5/57.5 kB 12.3 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "      1.1/1.1 MB 71.6 MB/s eta 0:00:00\n",
      "Collecting six>=1.12.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "      123.4/123.4 kB 15.3 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "      14.1/14.1 MB 119.7 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.10.0->-r /azureml-environment-setup/condaenv.pnaldeb1.requirements.txt (line 1)) (0.37.1)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "      62.8/62.8 kB 15.6 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "      4.9/4.9 MB 129.6 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n",
      "      169.8/169.8 kB 37.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "      781.3/781.3 kB 66.0 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "      93.3/93.3 kB 23.4 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "      232.7/232.7 kB 47.1 MB/s eta 0:00:00\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "      98.3/98.3 kB 24.1 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "      155.3/155.3 kB 28.4 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "      140.4/140.4 kB 30.7 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu==2.10.0->-r /azureml-environment-setup/condaenv.pnaldeb1.requirements.txt (line 1)) (2022.6.15)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "      61.5/61.5 kB 12.7 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "      77.1/77.1 kB 17.1 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "      151.7/151.7 kB 33.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, rsa, pyparsing, pyasn1-modules, protobuf, oauthlib, numpy, MarkupSafe, idna, gast, charset-normalizer, cachetools, absl-py, werkzeug, requests, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow-gpu\n",
      "Successfully installed MarkupSafe-2.1.1 absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 charset-normalizer-2.1.1 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.49.1 h5py-3.7.0 idna-3.4 importlib-metadata-5.0.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 numpy-1.23.3 oauthlib-3.2.1 opt-einsum-3.3.0 packaging-21.3 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.10.0 tensorflow-gpu-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 typing-extensions-4.3.0 urllib3-1.26.12 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.8.1\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 22.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container a7441c134696\n",
      " ---> 2b980166364c\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/bin:$PATH\n",
      " ---> Running in 178eaee41023\n",
      "Removing intermediate container 178eaee41023\n",
      " ---> 63b2c5d2bb96\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 3a23547849db\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in 9d607a286d1f\n",
      "Copying environment context\n",
      "Removing intermediate container 9d607a286d1f\n",
      " ---> 26444501705a\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 390ba479af06\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087\n",
      " ---> Running in 95b76fd0c4dd\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 95b76fd0c4dd\n",
      " ---> 9064029bdf1c\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087\n",
      " ---> Running in 226f4e327372\n",
      "Removing intermediate container 226f4e327372\n",
      " ---> e2527ac491d2\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 218c3246d13b\n",
      "Removing intermediate container 218c3246d13b\n",
      " ---> c2f219088121\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_33fbe20ad4dfdd08eb60ecf4a9723087 CONDA_PREFIX=/azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087\n",
      " ---> Running in 82d1a1ab3c0e\n",
      "Removing intermediate container 82d1a1ab3c0e\n",
      " ---> fde7d459f1f1\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 5e4c15fbb1b9\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 7231cc1915b5\n",
      "Removing intermediate container 7231cc1915b5\n",
      " ---> fe45ee9b65e6\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in 8c50a6f68ff8\n",
      "Removing intermediate container 8c50a6f68ff8\n",
      " ---> 0a4f7461bcee\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---> Running in ed5f5da16703\n",
      "Removing intermediate container ed5f5da16703\n",
      " ---> 9f5f59e3d6c6\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in 93d59c77e030\n",
      "Removing intermediate container 93d59c77e030\n",
      " ---> 5131f164ead5\n",
      "Successfully built 5131f164ead5\n",
      "Successfully tagged 9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d:latest\n",
      "Successfully tagged 9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d:1\n",
      "2022/10/05 06:01:51 Successfully executed container: acb_step_0\n",
      "2022/10/05 06:01:51 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/10/05 06:01:51 Pushing image: 9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d:1, attempt 1\n",
      "The push refers to repository [9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d]\n",
      "cfa4d0675bf6: Preparing\n",
      "2693497bb117: Preparing\n",
      "046f789d146c: Preparing\n",
      "7628941c0a01: Preparing\n",
      "c7bdb179405d: Preparing\n",
      "698cc51cb0e5: Preparing\n",
      "70046bf7c6b4: Preparing\n",
      "078ca256f5eb: Preparing\n",
      "109e2473853d: Preparing\n",
      "96b24c66764a: Preparing\n",
      "6e819efeaa51: Preparing\n",
      "1dfd7cfcdb19: Preparing\n",
      "676a122f28d4: Preparing\n",
      "932c31430e5a: Preparing\n",
      "429860fdba5f: Preparing\n",
      "a79e1698cb00: Preparing\n",
      "eab8455fa8dc: Preparing\n",
      "ae5bb9b8bfa6: Preparing\n",
      "3658c8f0b305: Preparing\n",
      "f6d431e5cea7: Preparing\n",
      "6dd112d20c0f: Preparing\n",
      "3fe7392a4af8: Preparing\n",
      "c4c9ec98503e: Preparing\n",
      "bebcfcbfcc83: Preparing\n",
      "2f41aa1fd57f: Preparing\n",
      "51a74c222e7c: Preparing\n",
      "dae13d47c191: Preparing\n",
      "1cd926d36d1f: Preparing\n",
      "58da15fdca3f: Preparing\n",
      "a3f2644599b5: Preparing\n",
      "a875a212c761: Preparing\n",
      "e47a183a6461: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "698cc51cb0e5: Waiting\n",
      "70046bf7c6b4: Waiting\n",
      "078ca256f5eb: Waiting\n",
      "109e2473853d: Waiting\n",
      "96b24c66764a: Waiting\n",
      "6e819efeaa51: Waiting\n",
      "1dfd7cfcdb19: Waiting\n",
      "676a122f28d4: Waiting\n",
      "932c31430e5a: Waiting\n",
      "429860fdba5f: Waiting\n",
      "a79e1698cb00: Waiting\n",
      "eab8455fa8dc: Waiting\n",
      "ae5bb9b8bfa6: Waiting\n",
      "3658c8f0b305: Waiting\n",
      "f6d431e5cea7: Waiting\n",
      "6dd112d20c0f: Waiting\n",
      "3fe7392a4af8: Waiting\n",
      "c4c9ec98503e: Waiting\n",
      "bebcfcbfcc83: Waiting\n",
      "2f41aa1fd57f: Waiting\n",
      "51a74c222e7c: Waiting\n",
      "dae13d47c191: Waiting\n",
      "1cd926d36d1f: Waiting\n",
      "58da15fdca3f: Waiting\n",
      "a3f2644599b5: Waiting\n",
      "a875a212c761: Waiting\n",
      "e47a183a6461: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "2693497bb117: Pushed\n",
      "7628941c0a01: Pushed\n",
      "c7bdb179405d: Pushed\n",
      "cfa4d0675bf6: Pushed\n",
      "046f789d146c: Pushed\n",
      "109e2473853d: Pushed\n",
      "70046bf7c6b4: Pushed\n",
      "078ca256f5eb: Pushed\n",
      "96b24c66764a: Pushed\n",
      "1dfd7cfcdb19: Pushed\n",
      "6e819efeaa51: Pushed\n",
      "676a122f28d4: Pushed\n",
      "932c31430e5a: Pushed\n",
      "429860fdba5f: Pushed\n",
      "a79e1698cb00: Pushed\n",
      "eab8455fa8dc: Pushed\n",
      "ae5bb9b8bfa6: Pushed\n",
      "f6d431e5cea7: Pushed\n",
      "6dd112d20c0f: Pushed\n",
      "3fe7392a4af8: Pushed\n",
      "2f41aa1fd57f: Pushed\n",
      "3658c8f0b305: Pushed\n",
      "dae13d47c191: Pushed\n",
      "\n",
      "1cd926d36d1f: Pushed\n",
      "58da15fdca3f: Pushed\n",
      "a3f2644599b5: Pushed\n",
      "a875a212c761: Pushed\n",
      "e47a183a6461: Pushed\n",
      "af7ed92504ae: Pushed\n",
      "698cc51cb0e5: Pushed\n",
      "bebcfcbfcc83: Pushed\n",
      "51a74c222e7c: Pushed\n",
      "c4c9ec98503e: Pushed\n",
      "1: digest: sha256:605866dcc520ddd09122aeb3b3dbd4f6187dd4deb2f7e70eebce8c4c62311503 size: 7258\n",
      "2022/10/05 06:08:10 Successfully pushed image: 9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d:1\n",
      "2022/10/05 06:08:10 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/10/05 06:08:10 Pushing image: 9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d:latest, attempt 1\n",
      "The push refers to repository [9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d]\n",
      "cfa4d0675bf6: Preparing\n",
      "2693497bb117: Preparing\n",
      "046f789d146c: Preparing\n",
      "7628941c0a01: Preparing\n",
      "c7bdb179405d: Preparing\n",
      "698cc51cb0e5: Preparing\n",
      "70046bf7c6b4: Preparing\n",
      "078ca256f5eb: Preparing\n",
      "109e2473853d: Preparing\n",
      "96b24c66764a: Preparing\n",
      "6e819efeaa51: Preparing\n",
      "1dfd7cfcdb19: Preparing\n",
      "676a122f28d4: Preparing\n",
      "932c31430e5a: Preparing\n",
      "429860fdba5f: Preparing\n",
      "a79e1698cb00: Preparing\n",
      "eab8455fa8dc: Preparing\n",
      "ae5bb9b8bfa6: Preparing\n",
      "3658c8f0b305: Preparing\n",
      "f6d431e5cea7: Preparing\n",
      "6dd112d20c0f: Preparing\n",
      "3fe7392a4af8: Preparing\n",
      "c4c9ec98503e: Preparing\n",
      "bebcfcbfcc83: Preparing\n",
      "2f41aa1fd57f: Preparing\n",
      "51a74c222e7c: Preparing\n",
      "dae13d47c191: Preparing\n",
      "1cd926d36d1f: Preparing\n",
      "58da15fdca3f: Preparing\n",
      "a3f2644599b5: Preparing\n",
      "a875a212c761: Preparing\n",
      "e47a183a6461: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "109e2473853d: Waiting\n",
      "96b24c66764a: Waiting\n",
      "6e819efeaa51: Waiting\n",
      "1dfd7cfcdb19: Waiting\n",
      "676a122f28d4: Waiting\n",
      "932c31430e5a: Waiting\n",
      "429860fdba5f: Waiting\n",
      "a79e1698cb00: Waiting\n",
      "eab8455fa8dc: Waiting\n",
      "ae5bb9b8bfa6: Waiting\n",
      "3658c8f0b305: Waiting\n",
      "f6d431e5cea7: Waiting\n",
      "6dd112d20c0f: Waiting\n",
      "3fe7392a4af8: Waiting\n",
      "c4c9ec98503e: Waiting\n",
      "bebcfcbfcc83: Waiting\n",
      "2f41aa1fd57f: Waiting\n",
      "51a74c222e7c: Waiting\n",
      "dae13d47c191: Waiting\n",
      "1cd926d36d1f: Waiting\n",
      "58da15fdca3f: Waiting\n",
      "a3f2644599b5: Waiting\n",
      "a875a212c761: Waiting\n",
      "e47a183a6461: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "698cc51cb0e5: Waiting\n",
      "70046bf7c6b4: Waiting\n",
      "078ca256f5eb: Waiting\n",
      "c7bdb179405d: Layer already exists\n",
      "7628941c0a01: Layer already exists\n",
      "046f789d146c: Layer already exists\n",
      "cfa4d0675bf6: Layer already exists\n",
      "698cc51cb0e5: Layer already exists\n",
      "2693497bb117: Layer already exists\n",
      "70046bf7c6b4: Layer already exists\n",
      "078ca256f5eb: Layer already exists\n",
      "96b24c66764a: Layer already exists\n",
      "109e2473853d: Layer already exists\n",
      "6e819efeaa51: Layer already exists\n",
      "1dfd7cfcdb19: Layer already exists\n",
      "429860fdba5f: Layer already exists\n",
      "932c31430e5a: Layer already exists\n",
      "eab8455fa8dc: Layer already exists\n",
      "676a122f28d4: Layer already exists\n",
      "a79e1698cb00: Layer already exists\n",
      "3658c8f0b305: Layer already exists\n",
      "6dd112d20c0f: Layer already exists\n",
      "3fe7392a4af8: Layer already exists\n",
      "f6d431e5cea7: Layer already exists\n",
      "ae5bb9b8bfa6: Layer already exists\n",
      "c4c9ec98503e: Layer already exists\n",
      "2f41aa1fd57f: Layer already exists\n",
      "bebcfcbfcc83: Layer already exists\n",
      "51a74c222e7c: Layer already exists\n",
      "1cd926d36d1f: Layer already exists\n",
      "dae13d47c191: Layer already exists\n",
      "a3f2644599b5: Layer already exists\n",
      "a875a212c761: Layer already exists\n",
      "58da15fdca3f: Layer already exists\n",
      "e47a183a6461: Layer already exists\n",
      "af7ed92504ae: Layer already exists\n",
      "latest: digest: sha256:605866dcc520ddd09122aeb3b3dbd4f6187dd4deb2f7e70eebce8c4c62311503 size: 7258\n",
      "2022/10/05 06:08:12 Successfully pushed image: 9f284df9d63640edbae10303c21d4b4f.azurecr.io/azureml/azureml_7e083e90b49a8884f2992d5c300d503d:latest\n",
      "2022/10/05 06:08:12 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 355.711039)\n",
      "2022/10/05 06:08:12 Populating digests for step ID: acb_step_0...\n",
      "2022/10/05 06:08:13 Successfully populated digests for step ID: acb_step_0\n",
      "2022/10/05 06:08:13 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 378.742138)\n",
      "2022/10/05 06:08:13 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.480127)\n",
      "2022/10/05 06:08:13 The following dependencies were found:\n",
      "2022/10/05 06:08:13 \n",
      "- image:\n",
      "    registry: 9f284df9d63640edbae10303c21d4b4f.azurecr.io\n",
      "    repository: azureml/azureml_7e083e90b49a8884f2992d5c300d503d\n",
      "    tag: latest\n",
      "    digest: sha256:605866dcc520ddd09122aeb3b3dbd4f6187dd4deb2f7e70eebce8c4c62311503\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04\n",
      "    digest: sha256:67c2d44ef91b157d07646d9fd3e28cb1f66ea3012b4b47b5dcc809a1285d6b19\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 9f284df9d63640edbae10303c21d4b4f.azurecr.io\n",
      "    repository: azureml/azureml_7e083e90b49a8884f2992d5c300d503d\n",
      "    tag: \"1\"\n",
      "    digest: sha256:605866dcc520ddd09122aeb3b3dbd4f6187dd4deb2f7e70eebce8c4c62311503\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04\n",
      "    digest: sha256:67c2d44ef91b157d07646d9fd3e28cb1f66ea3012b4b47b5dcc809a1285d6b19\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: ca3 was successful after 12m22s\n",
      "\n",
      "Streaming user_logs/std_log.txt\n",
      "===============================\n",
      "\n",
      "2022-10-05 06:23:26.994486: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 06:23:27.149212: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-05 06:23:27.926999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nccl-rdma-sharp-plugins/lib\n",
      "2022-10-05 06:23:27.927175: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_33fbe20ad4dfdd08eb60ecf4a9723087/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nccl-rdma-sharp-plugins/lib\n",
      "2022-10-05 06:23:27.927198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "##### List of available GPU #####\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2022-10-05 06:23:28.839641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 06:23:29.509818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10787 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 3ce7:00:00.0, compute capability: 3.7\n",
      "WARNING:tensorflow:From train.py:58: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n",
      "Epoch 1/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 5:43 - loss: 117.7281 - sparse_categorical_accuracy: 0.062\n",
      " 24/469 [>.............................] - ETA: 0s - loss: 21.7221 - sparse_categorical_accuracy: 0.5202 \n",
      " 45/469 [=>............................] - ETA: 0s - loss: 13.5807 - sparse_categorical_accuracy: 0.63\n",
      " 67/469 [===>..........................] - ETA: 0s - loss: 10.1150 - sparse_categorical_accuracy: 0.68\n",
      " 88/469 [====>.........................] - ETA: 0s - loss: 8.1738 - sparse_categorical_accuracy: 0.7119\n",
      "110/469 [======>.......................] - ETA: 0s - loss: 6.8950 - sparse_categorical_accuracy: 0.724\n",
      "132/469 [=======>......................] - ETA: 0s - loss: 5.9968 - sparse_categorical_accuracy: 0.728\n",
      "154/469 [========>.....................] - ETA: 0s - loss: 5.3279 - sparse_categorical_accuracy: 0.734\n",
      "175/469 [==========>...................] - ETA: 0s - loss: 4.8112 - sparse_categorical_accuracy: 0.740\n",
      "197/469 [===========>..................] - ETA: 0s - loss: 4.3809 - sparse_categorical_accuracy: 0.746\n",
      "217/469 [============>.................] - ETA: 0s - loss: 4.0645 - sparse_categorical_accuracy: 0.751\n",
      "236/469 [==============>...............] - ETA: 0s - loss: 3.8019 - sparse_categorical_accuracy: 0.755\n",
      "259/469 [===============>..............] - ETA: 0s - loss: 3.5458 - sparse_categorical_accuracy: 0.758\n",
      "280/469 [================>.............] - ETA: 0s - loss: 3.3354 - sparse_categorical_accuracy: 0.762\n",
      "303/469 [==================>...........] - ETA: 0s - loss: 3.1334 - sparse_categorical_accuracy: 0.768\n",
      "323/469 [===================>..........] - ETA: 0s - loss: 2.9829 - sparse_categorical_accuracy: 0.772\n",
      "342/469 [====================>.........] - ETA: 0s - loss: 2.8540 - sparse_categorical_accuracy: 0.776\n",
      "364/469 [======================>.......] - ETA: 0s - loss: 2.7207 - sparse_categorical_accuracy: 0.780\n",
      "385/469 [=======================>......] - ETA: 0s - loss: 2.6042 - sparse_categorical_accuracy: 0.784\n",
      "407/469 [=========================>....] - ETA: 0s - loss: 2.4997 - sparse_categorical_accuracy: 0.788\n",
      "429/469 [==========================>...] - ETA: 0s - loss: 2.4005 - sparse_categorical_accuracy: 0.791\n",
      "451/469 [===========================>..] - ETA: 0s - loss: 2.3057 - sparse_categorical_accuracy: 0.796\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 2.2349 - sparse_categorical_accuracy: 0.8008\n",
      "Epoch 2/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 17s - loss: 0.8138 - sparse_categorical_accuracy: 0.90\n",
      " 24/469 [>.............................] - ETA: 0s - loss: 0.5173 - sparse_categorical_accuracy: 0.8753\n",
      " 46/469 [=>............................] - ETA: 0s - loss: 0.4972 - sparse_categorical_accuracy: 0.882\n",
      " 67/469 [===>..........................] - ETA: 0s - loss: 0.4909 - sparse_categorical_accuracy: 0.884\n",
      " 89/469 [====>.........................] - ETA: 0s - loss: 0.4728 - sparse_categorical_accuracy: 0.884\n",
      "111/469 [======>.......................] - ETA: 0s - loss: 0.4845 - sparse_categorical_accuracy: 0.880\n",
      "132/469 [=======>......................] - ETA: 0s - loss: 0.4813 - sparse_categorical_accuracy: 0.879\n",
      "153/469 [========>.....................] - ETA: 0s - loss: 0.4667 - sparse_categorical_accuracy: 0.882\n",
      "174/469 [==========>...................] - ETA: 0s - loss: 0.4616 - sparse_categorical_accuracy: 0.884\n",
      "192/469 [===========>..................] - ETA: 0s - loss: 0.4584 - sparse_categorical_accuracy: 0.884\n",
      "213/469 [============>.................] - ETA: 0s - loss: 0.4556 - sparse_categorical_accuracy: 0.884\n",
      "226/469 [=============>................] - ETA: 0s - loss: 0.4495 - sparse_categorical_accuracy: 0.885\n",
      "245/469 [==============>...............] - ETA: 0s - loss: 0.4478 - sparse_categorical_accuracy: 0.885\n",
      "265/469 [===============>..............] - ETA: 0s - loss: 0.4440 - sparse_categorical_accuracy: 0.886\n",
      "287/469 [=================>............] - ETA: 0s - loss: 0.4394 - sparse_categorical_accuracy: 0.887\n",
      "310/469 [==================>...........] - ETA: 0s - loss: 0.4368 - sparse_categorical_accuracy: 0.888\n",
      "331/469 [====================>.........] - ETA: 0s - loss: 0.4319 - sparse_categorical_accuracy: 0.889\n",
      "354/469 [=====================>........] - ETA: 0s - loss: 0.4257 - sparse_categorical_accuracy: 0.890\n",
      "374/469 [======================>.......] - ETA: 0s - loss: 0.4204 - sparse_categorical_accuracy: 0.891\n",
      "395/469 [========================>.....] - ETA: 0s - loss: 0.4181 - sparse_categorical_accuracy: 0.892\n",
      "415/469 [=========================>....] - ETA: 0s - loss: 0.4138 - sparse_categorical_accuracy: 0.893\n",
      "436/469 [==========================>...] - ETA: 0s - loss: 0.4076 - sparse_categorical_accuracy: 0.894\n",
      "455/469 [============================>.] - ETA: 0s - loss: 0.3992 - sparse_categorical_accuracy: 0.896\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3959 - sparse_categorical_accuracy: 0.8980\n",
      "Epoch 3/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 18s - loss: 0.4814 - sparse_categorical_accuracy: 0.90\n",
      " 22/469 [>.............................] - ETA: 1s - loss: 0.3316 - sparse_categorical_accuracy: 0.9148\n",
      " 44/469 [=>............................] - ETA: 0s - loss: 0.3097 - sparse_categorical_accuracy: 0.919\n",
      " 65/469 [===>..........................] - ETA: 0s - loss: 0.3052 - sparse_categorical_accuracy: 0.920\n",
      " 85/469 [====>.........................] - ETA: 0s - loss: 0.3051 - sparse_categorical_accuracy: 0.920\n",
      "106/469 [=====>........................] - ETA: 0s - loss: 0.3001 - sparse_categorical_accuracy: 0.919\n",
      "128/469 [=======>......................] - ETA: 0s - loss: 0.2994 - sparse_categorical_accuracy: 0.919\n",
      "150/469 [========>.....................] - ETA: 0s - loss: 0.3038 - sparse_categorical_accuracy: 0.919\n",
      "172/469 [==========>...................] - ETA: 0s - loss: 0.2960 - sparse_categorical_accuracy: 0.920\n",
      "193/469 [===========>..................] - ETA: 0s - loss: 0.2942 - sparse_categorical_accuracy: 0.921\n",
      "213/469 [============>.................] - ETA: 0s - loss: 0.2915 - sparse_categorical_accuracy: 0.922\n",
      "236/469 [==============>...............] - ETA: 0s - loss: 0.2890 - sparse_categorical_accuracy: 0.922\n",
      "256/469 [===============>..............] - ETA: 0s - loss: 0.2893 - sparse_categorical_accuracy: 0.922\n",
      "277/469 [================>.............] - ETA: 0s - loss: 0.2847 - sparse_categorical_accuracy: 0.923\n",
      "299/469 [==================>...........] - ETA: 0s - loss: 0.2847 - sparse_categorical_accuracy: 0.924\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 0.2854 - sparse_categorical_accuracy: 0.924\n",
      "336/469 [====================>.........] - ETA: 0s - loss: 0.2821 - sparse_categorical_accuracy: 0.924\n",
      "359/469 [=====================>........] - ETA: 0s - loss: 0.2808 - sparse_categorical_accuracy: 0.925\n",
      "381/469 [=======================>......] - ETA: 0s - loss: 0.2785 - sparse_categorical_accuracy: 0.925\n",
      "403/469 [========================>.....] - ETA: 0s - loss: 0.2782 - sparse_categorical_accuracy: 0.925\n",
      "425/469 [==========================>...] - ETA: 0s - loss: 0.2747 - sparse_categorical_accuracy: 0.926\n",
      "447/469 [===========================>..] - ETA: 0s - loss: 0.2697 - sparse_categorical_accuracy: 0.927\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2646 - sparse_categorical_accuracy: 0.9290\n",
      "Epoch 4/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 18s - loss: 0.5016 - sparse_categorical_accuracy: 0.91\n",
      " 23/469 [>.............................] - ETA: 1s - loss: 0.2112 - sparse_categorical_accuracy: 0.9419\n",
      " 44/469 [=>............................] - ETA: 0s - loss: 0.2264 - sparse_categorical_accuracy: 0.941\n",
      " 63/469 [===>..........................] - ETA: 0s - loss: 0.2175 - sparse_categorical_accuracy: 0.941\n",
      " 83/469 [====>.........................] - ETA: 0s - loss: 0.2190 - sparse_categorical_accuracy: 0.941\n",
      "105/469 [=====>........................] - ETA: 0s - loss: 0.2177 - sparse_categorical_accuracy: 0.941\n",
      "128/469 [=======>......................] - ETA: 0s - loss: 0.2194 - sparse_categorical_accuracy: 0.940\n",
      "150/469 [========>.....................] - ETA: 0s - loss: 0.2144 - sparse_categorical_accuracy: 0.941\n",
      "169/469 [=========>....................] - ETA: 0s - loss: 0.2127 - sparse_categorical_accuracy: 0.941\n",
      "190/469 [===========>..................] - ETA: 0s - loss: 0.2131 - sparse_categorical_accuracy: 0.941\n",
      "212/469 [============>.................] - ETA: 0s - loss: 0.2147 - sparse_categorical_accuracy: 0.942\n",
      "235/469 [==============>...............] - ETA: 0s - loss: 0.2132 - sparse_categorical_accuracy: 0.942\n",
      "257/469 [===============>..............] - ETA: 0s - loss: 0.2135 - sparse_categorical_accuracy: 0.941\n",
      "279/469 [================>.............] - ETA: 0s - loss: 0.2113 - sparse_categorical_accuracy: 0.942\n",
      "301/469 [==================>...........] - ETA: 0s - loss: 0.2111 - sparse_categorical_accuracy: 0.942\n",
      "323/469 [===================>..........] - ETA: 0s - loss: 0.2119 - sparse_categorical_accuracy: 0.942\n",
      "346/469 [=====================>........] - ETA: 0s - loss: 0.2119 - sparse_categorical_accuracy: 0.942\n",
      "369/469 [======================>.......] - ETA: 0s - loss: 0.2136 - sparse_categorical_accuracy: 0.941\n",
      "391/469 [========================>.....] - ETA: 0s - loss: 0.2122 - sparse_categorical_accuracy: 0.942\n",
      "412/469 [=========================>....] - ETA: 0s - loss: 0.2110 - sparse_categorical_accuracy: 0.942\n",
      "433/469 [==========================>...] - ETA: 0s - loss: 0.2093 - sparse_categorical_accuracy: 0.943\n",
      "450/469 [===========================>..] - ETA: 0s - loss: 0.2062 - sparse_categorical_accuracy: 0.943\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2034 - sparse_categorical_accuracy: 0.9448\n",
      "Epoch 5/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 18s - loss: 0.2062 - sparse_categorical_accuracy: 0.93\n",
      " 24/469 [>.............................] - ETA: 1s - loss: 0.1785 - sparse_categorical_accuracy: 0.9525\n",
      " 45/469 [=>............................] - ETA: 1s - loss: 0.1731 - sparse_categorical_accuracy: 0.952\n",
      " 68/469 [===>..........................] - ETA: 0s - loss: 0.1858 - sparse_categorical_accuracy: 0.950\n",
      " 91/469 [====>.........................] - ETA: 0s - loss: 0.1799 - sparse_categorical_accuracy: 0.951\n",
      "113/469 [======>.......................] - ETA: 0s - loss: 0.1804 - sparse_categorical_accuracy: 0.951\n",
      "134/469 [=======>......................] - ETA: 0s - loss: 0.1803 - sparse_categorical_accuracy: 0.950\n",
      "155/469 [========>.....................] - ETA: 0s - loss: 0.1766 - sparse_categorical_accuracy: 0.951\n",
      "177/469 [==========>...................] - ETA: 0s - loss: 0.1757 - sparse_categorical_accuracy: 0.951\n",
      "198/469 [===========>..................] - ETA: 0s - loss: 0.1774 - sparse_categorical_accuracy: 0.951\n",
      "219/469 [=============>................] - ETA: 0s - loss: 0.1752 - sparse_categorical_accuracy: 0.951\n",
      "242/469 [==============>...............] - ETA: 0s - loss: 0.1759 - sparse_categorical_accuracy: 0.951\n",
      "262/469 [===============>..............] - ETA: 0s - loss: 0.1742 - sparse_categorical_accuracy: 0.951\n",
      "283/469 [=================>............] - ETA: 0s - loss: 0.1742 - sparse_categorical_accuracy: 0.951\n",
      "305/469 [==================>...........] - ETA: 0s - loss: 0.1757 - sparse_categorical_accuracy: 0.951\n",
      "327/469 [===================>..........] - ETA: 0s - loss: 0.1757 - sparse_categorical_accuracy: 0.951\n",
      "348/469 [=====================>........] - ETA: 0s - loss: 0.1746 - sparse_categorical_accuracy: 0.951\n",
      "370/469 [======================>.......] - ETA: 0s - loss: 0.1733 - sparse_categorical_accuracy: 0.951\n",
      "392/469 [========================>.....] - ETA: 0s - loss: 0.1734 - sparse_categorical_accuracy: 0.951\n",
      "413/469 [=========================>....] - ETA: 0s - loss: 0.1728 - sparse_categorical_accuracy: 0.951\n",
      "435/469 [==========================>...] - ETA: 0s - loss: 0.1714 - sparse_categorical_accuracy: 0.952\n",
      "454/469 [============================>.] - ETA: 0s - loss: 0.1689 - sparse_categorical_accuracy: 0.952\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9535\n",
      "Epoch 6/6\n",
      "\n",
      "  1/469 [..............................] - ETA: 23s - loss: 0.1919 - sparse_categorical_accuracy: 0.92\n",
      " 24/469 [>.............................] - ETA: 0s - loss: 0.1485 - sparse_categorical_accuracy: 0.9577\n",
      " 45/469 [=>............................] - ETA: 0s - loss: 0.1414 - sparse_categorical_accuracy: 0.960\n",
      " 63/469 [===>..........................] - ETA: 1s - loss: 0.1399 - sparse_categorical_accuracy: 0.962\n",
      " 86/469 [====>.........................] - ETA: 0s - loss: 0.1416 - sparse_categorical_accuracy: 0.961\n",
      "109/469 [=====>........................] - ETA: 0s - loss: 0.1458 - sparse_categorical_accuracy: 0.959\n",
      "131/469 [=======>......................] - ETA: 0s - loss: 0.1444 - sparse_categorical_accuracy: 0.959\n",
      "153/469 [========>.....................] - ETA: 0s - loss: 0.1420 - sparse_categorical_accuracy: 0.960\n",
      "173/469 [==========>...................] - ETA: 0s - loss: 0.1421 - sparse_categorical_accuracy: 0.960\n",
      "194/469 [===========>..................] - ETA: 0s - loss: 0.1407 - sparse_categorical_accuracy: 0.960\n",
      "218/469 [============>.................] - ETA: 0s - loss: 0.1420 - sparse_categorical_accuracy: 0.960\n",
      "231/469 [=============>................] - ETA: 0s - loss: 0.1418 - sparse_categorical_accuracy: 0.960\n",
      "252/469 [===============>..............] - ETA: 0s - loss: 0.1411 - sparse_categorical_accuracy: 0.959\n",
      "275/469 [================>.............] - ETA: 0s - loss: 0.1404 - sparse_categorical_accuracy: 0.959\n",
      "296/469 [=================>............] - ETA: 0s - loss: 0.1396 - sparse_categorical_accuracy: 0.960\n",
      "317/469 [===================>..........] - ETA: 0s - loss: 0.1403 - sparse_categorical_accuracy: 0.960\n",
      "339/469 [====================>.........] - ETA: 0s - loss: 0.1403 - sparse_categorical_accuracy: 0.959\n",
      "362/469 [======================>.......] - ETA: 0s - loss: 0.1400 - sparse_categorical_accuracy: 0.959\n",
      "382/469 [=======================>......] - ETA: 0s - loss: 0.1417 - sparse_categorical_accuracy: 0.959\n",
      "404/469 [========================>.....] - ETA: 0s - loss: 0.1411 - sparse_categorical_accuracy: 0.959\n",
      "426/469 [==========================>...] - ETA: 0s - loss: 0.1407 - sparse_categorical_accuracy: 0.959\n",
      "447/469 [===========================>..] - ETA: 0s - loss: 0.1389 - sparse_categorical_accuracy: 0.960\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1369 - sparse_categorical_accuracy: 0.9608\n",
      "current working directory :  /mnt/azureml/cr/j/4e18b599874746a3a5a0854086b9d231/exe/wd\n",
      "model folder :  ./outputs/mnist_tf_model\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: tf_remote_experiment_1664949349_0c9b7841\n",
      "Web View: https://ml.azure.com/runs/tf_remote_experiment_1664949349_0c9b7841?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'tf_remote_experiment_1664949349_0c9b7841',\n",
       " 'target': 'myvm01',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-10-05T06:21:22.340264Z',\n",
       " 'endTimeUtc': '2022-10-05T06:23:42.428514Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n",
       "  'ContentSnapshotId': '854efebe-1b17-4b1c-bd49-a1410fb8e940',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '16c18986-c760-49b0-a222-eeb89a5f9262'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__16c18986', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data_folder', 'DatasetConsumptionConfig:input__16c18986'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'myvm01',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__16c18986': {'dataLocation': {'dataset': {'id': '16c18986-c760-49b0-a222-eeb89a5f9262',\n",
       "      'name': 'mnist_dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None,\n",
       "     'type': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__16c18986',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'test-remote-gpu-env',\n",
       "   'version': '3',\n",
       "   'assetId': 'azureml://locations/eastus/workspaces/9f284df9-d636-40ed-bae1-0303c21d4b4f/environments/test-remote-gpu-env/versions/3',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.8', {'pip': ['tensorflow-gpu==2.10.0']}],\n",
       "     'channels': ['anaconda', 'conda-forge']},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=dZm8%2BMmzNGgBRvwsl7jQDvH5rDjuJd8EFsTVJ88jt6I%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A12%3A14Z&se=2022-10-05T14%3A22%3A14Z&sp=r',\n",
       "  'user_logs/std_log.txt': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=JUTnD5lC0vQzLzgmQmdLJ7Fvms6m0yg2S85zdPHKJpc%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=bgIkSWaH7%2BzXyJ%2BVjGZU6T8F5gyjvukM%2FZg%2Fspkqncg%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/data_capability/data-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=DJIQ5dDcKtQJ3bUCqoEBLuAtyQC4vDQxoJaeiupY6P0%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/data_capability/rslex.log.2022-10-05-06': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/data_capability/rslex.log.2022-10-05-06?sv=2019-07-07&sr=b&sig=9Ynvut21CrO6MyAEd24ScKDzAprYKa5gnTj6yGBGCJg%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=t9maanI8ZCsS6Scy30Qflv6bv1PxzACQGKRM%2B8Vpxcs%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=Z%2BU7q4avOc1jPdLMURMhbYU7AofqzuXFS5gDk25iWao%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=NoUgJupfRPMUKBKnQVWI5TvXDHc98qp4nZmLWRK4hZU%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=BSwYMI7hACNhOYlF8E5R7xqhrHqSL7DUU29g01KBYi0%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://ws012900856943.blob.core.windows.net/azureml/ExperimentRun/dcid.tf_remote_experiment_1664949349_0c9b7841/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=%2BKqlK%2FxFOxxrzBKX%2BzhC2%2F6Zz0Nhto5PjxlckctVMzg%3D&skoid=9f897d78-668e-424c-8b09-9c56c219a5fb&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-10-05T04%3A52%3A43Z&ske=2022-10-06T13%3A02%3A43Z&sks=b&skv=2019-07-07&st=2022-10-05T06%3A14%3A18Z&se=2022-10-05T14%3A24%3A18Z&sp=r'},\n",
       " 'submittedBy': 'Tsuyoshi Matsuzaki'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = ScriptRunConfig(\n",
    "    source_directory='./script',\n",
    "    script='train.py',\n",
    "    arguments=['--data_folder', dataset.as_mount()],\n",
    "    compute_target=compute_target,\n",
    "    environment=env,\n",
    "    docker_runtime_config=DockerConfiguration(use_docker=True))\n",
    "\n",
    "# submit and run !\n",
    "exp = Experiment(workspace=ws, name='tf_remote_experiment')\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 : Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.    \n",
    "But if you want to clean up, please run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cluster (nbodes) and remove from AML workspace\n",
    "mycompute = AmlCompute(workspace=ws, name='myvm01')\n",
    "mycompute.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'currentNodeCount': 1, 'targetNodeCount': 1, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 1, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-08-31T04:52:16.858000+00:00', 'errors': None, 'creationTime': '2021-08-31T04:45:45.747268+00:00', 'modifiedTime': '2021-08-31T04:46:11.291359+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 1, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC4AS_T4_V3'}\n"
     ]
    }
   ],
   "source": [
    "# get a status for the current cluster.\n",
    "print(mycompute.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
