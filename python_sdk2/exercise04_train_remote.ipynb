{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise04 : Train on Remote GPU Virtual Machine\n",
    "\n",
    "Now we run our previous sample (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") on remote virtual machine with GPU utilized.\n",
    "\n",
    "> Note : If you don't have GPU quota, you can also run this example on CPU.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MLClient\n",
    "\n",
    "Replace below's branket's string with your subscription id, resource group name, and AML workspace name.<br>\n",
    "(I note that creating ```MLClient``` will not connect to AML workspace, and the client initialization is lazy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DeviceCodeCredential, TokenCachePersistenceOptions\n",
    "\n",
    "# When you run on remote\n",
    "cache_opt = TokenCachePersistenceOptions(allow_unencrypted_storage=True)\n",
    "cred = DeviceCodeCredential(cache_persistence_options=cache_opt)\n",
    "\n",
    "# # When you run on Azure ML Notebook\n",
    "# from azure.identity import DefaultAzureCredential\n",
    "# cred = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=cred,\n",
    "    subscription_id=\"{SUBSCRIPTION ID}\",\n",
    "    resource_group_name=\"{RESOURCE GROUP NAME}\",\n",
    "    workspace_name=\"{AML WORKSPACE NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory and save Python script as ```./script/train.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train.py\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "# device test\n",
    "print(\"##### List of available GPU #####\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data_folder\",\n",
    "    type=str,\n",
    "    default=\"./data/train\",\n",
    "    help=\"Folder path for input data\")\n",
    "parser.add_argument(\n",
    "    \"--model_folder\",\n",
    "    type=str,\n",
    "    default=\"./outputs\",  # AML experiments outputs folder\n",
    "    help=\"Folder path for model output\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=\"0.001\",\n",
    "    help=\"Learning Rate\")\n",
    "parser.add_argument(\n",
    "    \"--first_layer\",\n",
    "    type=int,\n",
    "    default=\"128\",\n",
    "    help=\"Neuron number for the first hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--second_layer\",\n",
    "    type=int,\n",
    "    default=\"64\",\n",
    "    help=\"Neuron number for the second hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--epochs_num\",\n",
    "    type=int,\n",
    "    default=\"6\",\n",
    "    help=\"Number of epochs\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# build model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(FLAGS.first_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(FLAGS.second_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(FLAGS.learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# run training\n",
    "train_data = tf.data.experimental.load(FLAGS.data_folder)\n",
    "model.fit(\n",
    "    train_data.shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=FLAGS.epochs_num\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_path = os.path.join(FLAGS.model_folder, \"mnist_tf_model\")\n",
    "model.save(model_path)\n",
    "print(\"current working directory : \", os.getcwd())\n",
    "print(\"model folder : \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on remote VM\n",
    "\n",
    "Now let's start to integrate with AML and automate training on remote virtual machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Create new remote virtual machine\n",
    "\n",
    "Create your new reomte virtual machine with GPU.<br>\n",
    "Before starting, **please check the following**.\n",
    "\n",
    "- Make sure that the following size (in the following script, ```Standard_NC4as_T4_v3```) is supported in the location (in which AML workspace resides).\n",
    "- You should have quota for ML GPU VM in your Azure subscription. If you don't have, please request quota in Azure Portal.\n",
    "\n",
    "**If you don't have any quota for GPU, please use CPU VM (such as, Standard_D2_v2).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FB56HDWZ5 to authenticate.\n",
      "creating new.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(\"myvm01\")\n",
    "    print(\"found existing: \", compute_target.name)\n",
    "except Exception:\n",
    "    print(\"creating new.\")\n",
    "    compute_target = AmlCompute(\n",
    "        name=\"myvm01\",\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_NC4as_T4_v3\", # change such as Standard_NC6 or Standard_D2_v2 if needed\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    compute_target = ml_client.begin_create_or_update(compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting 0 in ```min_instances```, the node will be terminated if it's inactive. (You can save money.)\n",
    "\n",
    "> Note : By setting appropriate time duration in ```idle_time_before_scale_down``` parameter, you can prevent scaling-down when the training has finished. (Otherwise, it will scale down in 120 seconds after the training has finished, and the next training will slow to start because of cluster resizing.)\n",
    "\n",
    "> Note : You can also attach an existing virtual machine (bring your own compute resource) as a compute target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Submit training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a training job with above compute and environment.\n",
    "\n",
    "In this example, I use the registered data asset named ```mnist_data``` and mount this data in my compute target. (Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation.)<br>\n",
    "In order to use data asset in AML, set ```{DATA_NAME}:{DATA_VERSION}``` or ```{DATA_NAME}@latest``` for the latest version of assets as follows.\n",
    "\n",
    "See the progress and results in job view on [AML Studio](https://ml.azure.com/).\n",
    "\n",
    "> Note : Here I use AML built-in environment (```AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu```), but you can build and use your own environment.<br>\n",
    "> In the later example in this notebook, I'll run the same script with my own environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script (0.0 MBs): 100%|█████████████████████████████████████████| 1862/1862 [00:00<00:00, 283662.43it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "\n",
    "# create the command\n",
    "job = command(\n",
    "    code=\"./script\",\n",
    "    command=\"python train.py --data_folder ${{inputs.mnist_tf}}/train\",\n",
    "    inputs={\n",
    "        \"mnist_tf\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"mnist_data@latest\",\n",
    "        ),\n",
    "    },\n",
    "    environment=\"AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu@latest\",\n",
    "    compute=\"myvm01\",\n",
    "    display_name=\"tf_remote_experiment\",\n",
    "    experiment_name=\"tf_remote_experiment\",\n",
    "    description=\"This is example\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get job name as follows.<br>\n",
    "Job name is always used to get detailed information about job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dynamic_brush_6xv178xzwd'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please wait until the job is completed.\n",
    "\n",
    "You can see current status (progress) with [AML studio UI](https://ml.azure.com/) (see \"Jobs\" pane) or with the following CLI command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>tf_remote_experiment</td><td>dynamic_brush_6xv178xzwd</td><td>command</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/dynamic_brush_6xv178xzwd?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AML-rg/workspaces/ws01&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'type': 'command', 'status': 'Completed', 'log_files': None, 'name': 'dynamic_brush_6xv178xzwd', 'description': 'This is example', 'tags': {'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":0}'}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '7ad0ffeb-55ec-4cbb-8685-8da3fb50497c', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'id': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/dynamic_brush_6xv178xzwd', 'Resource__source_path': None, 'base_path': '/home/tsmatsuz/python_sdk2', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2cea49e490>, 'serialize': <msrest.serialization.Serializer object at 0x7f2cea53a3d0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'tf_remote_experiment', 'experiment_name': 'tf_remote_experiment', 'compute': 'myvm01', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7f2cea44b460>, 'Studio': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7f2cea44b9d0>}, 'job_inputs': {'mnist_tf': {'type': 'uri_folder', 'path': 'mnist_data:1', 'mode': 'ro_mount'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.dynamic_brush_6xv178xzwd', 'mode': 'rw_mount'}}, 'inputs': {'mnist_tf': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7f2cea44b130>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.PipelineOutputBase object at 0x7f2cea49e4c0>}, 'component': CommandComponent({'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'name': 'dynamic_brush_6xv178xzwd', 'description': 'This is example', 'tags': {'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":0}'}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2cea49e490>, 'serialize': <msrest.serialization.Serializer object at 0x7f2ceadc1970>, 'command': 'python train.py --data_folder ${{inputs.mnist_tf}}/train', 'code': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/cbcff080-bc19-4923-b412-b0f40669a2bb/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu/versions/23', 'distribution': None, 'resources': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'tf_remote_experiment', 'is_deterministic': True, 'inputs': {'mnist_tf': {'type': 'uri_folder', 'path': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/data/mnist_data/versions/1', 'mode': 'ro_mount'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.dynamic_brush_6xv178xzwd', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Completed', 'parameters': {}}, 'func': <function [component] tf_remote_experiment at 0x7f2cea3f5e50>}), 'kwargs': {'services': {'Tracking': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7f2cea44b460>, 'Studio': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7f2cea44b9d0>}, 'status': 'Completed', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2cea49e490>}, 'instance_id': 'cd14a1f2-d70c-4cbc-befc-bab6dd562935', 'source': 'BUILDER', 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu:23', 'resources': {'instance_count': 1, 'shm_size': '2g', 'properties': {}}, 'swept': False})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.get(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Download results and evaluate\n",
    "\n",
    "After the training has completed, go to [Azure ML studio UI](https://ml.azure.com/).<br>\n",
    "You can then see the saved model in outputs directory.\n",
    "\n",
    "![Saved Outputs](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20220225_Experiment_Outputs.jpg)\n",
    "\n",
    "Now let's check the generated model in local computer.<br>\n",
    "Download artifacts (including the generated model in outputs) with SDK as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.dynamic_brush_6xv178xzwd to artifacts\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.download(name=returned_job.name, download_path=\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the downloaded result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 00:36:25.639683: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-05 00:36:25.817034: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-05 00:36:25.817090: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-05 00:36:25.861734: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-05 00:36:27.051673: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-05 00:36:27.051806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-05 00:36:27.051823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-05 00:36:28.031593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-05 00:36:28.031731: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-05 00:36:28.031777: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (client1004): /proc/driver/nvidia/version does not exist\n",
      "2022-10-05 00:36:28.032129: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 7, True 7\n",
      "Predicted 2, True 2\n",
      "Predicted 1, True 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test_data = tf.data.Dataset.load(\"./data/test\")\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"./artifacts/outputs/mnist_tf_model\")\n",
    "for image, true_value in test_data.take(3):\n",
    "    pred_output = loaded_model(tf.expand_dims(image, axis=0))\n",
    "    pred_value = tf.math.argmax(pred_output, axis=-1).numpy().item()\n",
    "    print(\"Predicted {}, True {}\".format(pred_value, true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Register Model\n",
    "\n",
    "Now upload (register) the downloaded model into AML model management.\n",
    "\n",
    "> Note : You can directly register model file from run history as follows.<br>\n",
    "> ```\n",
    "> run_model = Model(\n",
    ">   path=\"azureml://subscriptions/XXX/resourceGroups/XXX/workspaces/XXX/jobs/XXX/outputs/artifacts/outputs/mnist_tf_model\",\n",
    ">   type=\"custom_model\",\n",
    ">   name=\"mnist_model_test\",\n",
    "> )\n",
    "> ml_client.models.create_or_update(run_model)\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading mnist_tf_model (1.42 MBs): 100%|████████████████████████| 1418402/1418402 [00:00<00:00, 12633967.98it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'mnist_model_test', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/models/mnist_model_test/versions/1', 'Resource__source_path': None, 'base_path': '/home/tsmatsuz/python_sdk2', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f2ce8fa9fa0>, 'serialize': <msrest.serialization.Serializer object at 0x7f2ce8ffbd00>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/workspaces/ws01/datastores/workspaceblobstore/paths/LocalUpload/137eb5837c85f2a0f2959021fdeb9038/mnist_tf_model', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "#from azure.ai.ml.constants import ModelType\n",
    "\n",
    "file_model = Model(\n",
    "    path=\"./artifacts/outputs/mnist_tf_model\",\n",
    "    type=\"custom_model\",\n",
    "    name=\"mnist_model_test\",\n",
    ")\n",
    "ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Step 5 : Train with your own environment\n",
    "\n",
    "**This is not mandatory. (You can skip this section.)**\n",
    "\n",
    "You can also build your own environment with custom docker image.<br>\n",
    "Here we create a new docker environments for running scripts, and run the same training with this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I create conda dependancies yaml and save as ```04_conda_pydata.yml```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 04_conda_pydata.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 04_conda_pydata.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "- python=3.8\n",
    "- pip:\n",
    "  - tensorflow-gpu==2.10.0\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register custom environment (named ```test-remote-gpu-env```) in AML with previous conda configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "myenv = Environment(\n",
    "    name=\"test-remote-gpu-env\",\n",
    "    description=\"This is example\",\n",
    "    conda_file=\"04_conda_pydata.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:latest\",\n",
    ")\n",
    "myenv = ml_client.environments.create_or_update(myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [AML Studio UI](https://ml.azure.com/) and click \"Environments\". Next, click \"Custom environments\" tab and select the above environment.<br>\n",
    "Please wait until the environment image build status is succeeded.\n",
    "\n",
    "![Environment status](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20221220_Environment_Status.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train script with above custom environment.\n",
    "\n",
    "It will take a long time (over 30 minutes) for the first time run, because it'll pull base image, generate new image (custom environment), start nodes in cluster, and run scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the command\n",
    "job = command(\n",
    "    code=\"./script\",\n",
    "    command=\"python train.py --data_folder ${{inputs.mnist_tf}}/train\",\n",
    "    inputs={\n",
    "        \"mnist_tf\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"mnist_data@latest\",\n",
    "        ),\n",
    "    },\n",
    "    environment=\"test-remote-gpu-env@latest\",\n",
    "    compute=\"myvm01\",\n",
    "    display_name=\"tf_remote_experiment\",\n",
    "    experiment_name=\"tf_remote_experiment\",\n",
    "    description=\"This is example\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting compute myvm01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......"
     ]
    }
   ],
   "source": [
    "ml_client.compute.begin_delete(\"myvm01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
