{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise07 : Hyperparameter Tuning (Sweep Job)\n",
    "\n",
    "AML provides framework-independent hyperparameter tuning capability.<br>\n",
    "You can quickly search optimal parameters with scaled training workloads. This capability also works with metrics in AML logging.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MLClient\n",
    "\n",
    "Replace below's branket's string with your subscription id, resource group name, and AML workspace name.<br>\n",
    "(I note that creating ```MLClient``` will not connect to AML workspace, and the client initialization is lazy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DeviceCodeCredential, TokenCachePersistenceOptions\n",
    "\n",
    "# When you run on remote\n",
    "cache_opt = TokenCachePersistenceOptions(allow_unencrypted_storage=True)\n",
    "cred = DeviceCodeCredential(cache_persistence_options=cache_opt)\n",
    "\n",
    "# # When you run on Azure ML Notebook\n",
    "# from azure.identity import DefaultAzureCredential\n",
    "# cred = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=cred,\n",
    "    subscription_id=\"{SUBSCRIPTION ID}\",\n",
    "    resource_group_name=\"{RESOURCE GROUP NAME}\",\n",
    "    workspace_name=\"{AML WORKSPACE NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training code\n",
    "\n",
    "First, you must save your training code.    \n",
    "Here I should use the source code in \"[Exercise06 : Track Logs and Metrics](./exercise06_experimentation.ipynb)\", which sends logs into AML run history. (The metrics will be tracked in hyper-parameter tuning (sweep) job.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save source code as ```./script/train_expriment.py```.<br>\n",
    "This source code is the exact same source code as one in \"[Exercise06 : Track Logs and Metrics](./exercise06_experimentation.ipynb)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/train_experiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_experiment.py\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import mlflow ##### Modified\n",
    "mlflow.tensorflow.autolog() ##### Modified\n",
    "\n",
    "### You can also manually log as follows (Here we use autolog())\n",
    "# mlflow.log_params({\n",
    "#     'learning_rate': FLAGS.learning_rate,\n",
    "#     '1st_layer': FLAGS.first_layer,\n",
    "#     '2nd_layer': FLAGS.second_layer})\n",
    "# mlflow.log_metrics(\n",
    "#     {'training_accuracy': result_accuracy, 'training_loss': result_loss},\n",
    "#     step=result_step)\n",
    "\n",
    "# device test\n",
    "print(\"##### List of available GPU #####\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data_folder\",\n",
    "    type=str,\n",
    "    default=\"./data/train\",\n",
    "    help=\"Folder path for input data\")\n",
    "parser.add_argument(\n",
    "    \"--model_folder\",\n",
    "    type=str,\n",
    "    default=\"./outputs\",  # AML experiments outputs folder\n",
    "    help=\"Folder path for model output\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=\"0.001\",\n",
    "    help=\"Learning Rate\")\n",
    "parser.add_argument(\n",
    "    \"--first_layer\",\n",
    "    type=int,\n",
    "    default=\"128\",\n",
    "    help=\"Neuron number for the first hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--second_layer\",\n",
    "    type=int,\n",
    "    default=\"64\",\n",
    "    help=\"Neuron number for the second hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--epochs_num\",\n",
    "    type=int,\n",
    "    default=\"6\",\n",
    "    help=\"Number of epochs\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# build model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(FLAGS.first_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(FLAGS.second_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(FLAGS.learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# run training\n",
    "train_data = tf.data.experimental.load(FLAGS.data_folder)\n",
    "model.fit(\n",
    "    train_data.shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=FLAGS.epochs_num\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_path = os.path.join(FLAGS.model_folder, \"mnist_tf_model\")\n",
    "model.save(model_path)\n",
    "print(\"current working directory : \", os.getcwd())\n",
    "print(\"model folder : \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML compute\n",
    "\n",
    "Create AML compute pool for computing environment.<br>\n",
    "Here I create a cluster with max 4 instances to scale sweep job.\n",
    "\n",
    "> Note : By setting appropriate time duration in ```idle_time_before_scale_down``` parameter, you can prevent scaling-down when the training has finished. (Otherwise, it will scale down in 120 seconds after the training has finished, and the next training will slow to start because of cluster resizing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AX9T4BVTB to authenticate.\n",
      "creating new.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(\"hypertest01\")\n",
    "    print(\"found existing: \", compute_target.name)\n",
    "except Exception:\n",
    "    print(\"creating new.\")\n",
    "    compute_target = AmlCompute(\n",
    "        name=\"hypertest01\",\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_D2_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    compute_target = ml_client.begin_create_or_update(compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML environment\n",
    "\n",
    "As I have mentioned in \"[Exercise06 : Track Logs and Metrics](./exercise06_experimentation.ipynb)\", we should use an environment with ```mlflow``` and ```azureml-mlflow``` installed.\n",
    "\n",
    "**If you have already created custom environment in [Exercise06](./exercise06_experimentation.ipynb), you don't need to run the following command.** (Because this custom environment already exists.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 06_conda_pydata_for_logging.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "- python=3.8\n",
    "- pip:\n",
    "  - tensorflow-gpu==2.10.0\n",
    "  - mlflow\n",
    "  - azureml-mlflow\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "myenv = Environment(\n",
    "    name=\"test-remote-cpu-env-for-logging\",\n",
    "    description=\"This is example\",\n",
    "    conda_file=\"06_conda_pydata_for_logging.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    ")\n",
    "myenv = ml_client.environments.create_or_update(myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [AML Studio UI](https://ml.azure.com/) and click \"Environments\". Next, click \"Custom environments\" tab and select the above environment.<br>\n",
    "Please wait until the environment image build status is succeeded.\n",
    "\n",
    "![Environment status](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20221220_Environment_Status.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a job with hyper-parameter's search\n",
    "\n",
    "Now submit a job, in which multiple trainings will run depending on different hyper-parameters.<br>\n",
    "In this example, we monitor training accuracy depending on 3 arguments - ```--learning_rate```, ```--first_layer```, and ```--second_layer```. Each arguments can have 3 different values (and then total 27 trials can be run), but here I set maximum 20 trials to run, in which the values of arguments are randomly picked up.<br>\n",
    "These trials will be parallelized on above 4 node to speed up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define an usual command job without hyper-parameter (sweep) settings.\n",
    "\n",
    "> Note : In this example, I also use the registered data asset named ```mnist_data``` to mount in your compute target. Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "\n",
    "job = command(\n",
    "    code=\"./script\",\n",
    "    command=\"python train_experiment.py --data_folder ${{inputs.mnist_tf}}/train --learning_rate ${{inputs.learning_rate}} --first_layer ${{inputs.first_layer}} --second_layer ${{inputs.second_layer}}\",\n",
    "    inputs={\n",
    "        \"mnist_tf\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"mnist_data@latest\",\n",
    "        ),\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"first_layer\": 100,\n",
    "        \"second_layer\": 30,\n",
    "    },\n",
    "    environment=\"test-remote-cpu-env-for-logging@latest\",\n",
    "    compute=\"hypertest01\",\n",
    "    display_name=\"hyperdrive_test\",\n",
    "    experiment_name=\"hyperdrive_test\",\n",
    "    description=\"This is example\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply the sweep settings to the above generated job.\n",
    "\n",
    "By ```objective``` setting, the accuracy in each training is tracked and it's evaluated to maximize. (```sparse_categorical_accuracy``` is the metrics name of MLflow tracking in this training.)\n",
    "\n",
    "For ```sampling_algorithm```, you can use ```grid```, ```random```, and ```bayesian```.<br>\n",
    "You can also specify an early termnination policy (```early_termination```), in which the training will terminate if the primary metric falls outside of some threshold. (Here we don't apply early termination.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "# Customize inputs for sweep\n",
    "job_for_sweep = job(\n",
    "    learning_rate=Choice(values=[0.001, 0.005, 0.009]),\n",
    "    first_layer=Choice(values=[100, 125, 150]),\n",
    "    second_layer=Choice(values=[30, 60, 90]),\n",
    ")\n",
    "\n",
    "# Apply sweep for parameters\n",
    "sweep_job = job_for_sweep.sweep(\n",
    "    compute=\"hypertest01\",\n",
    "    sampling_algorithm=\"random\",\n",
    "    primary_metric=\"sparse_categorical_accuracy\",\n",
    "    goal=\"Maximize\",\n",
    ")\n",
    "sweep_job.set_limits(max_total_trials=20, max_concurrent_trials=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's submit the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_job = ml_client.create_or_update(sweep_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the link in the following output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>python_sdk2</td><td>neat_spoon_4r4xqk7mgd</td><td>sweep</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/neat_spoon_4r4xqk7mgd?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AML-rg/workspaces/ws01&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "SweepJob({'type': 'sweep', 'status': 'Running', 'log_files': None, 'name': 'neat_spoon_4r4xqk7mgd', 'description': None, 'tags': {'_aml_system_max_concurrent_jobs': '4', '_aml_system_max_total_jobs': '20', '_aml_system_max_duration_minutes': '86400', '_aml_system_policy_config': '{\"name\":\"Default\",\"properties\":{}}', '_aml_system_generator_config': '{\"name\":\"RANDOM\",\"parameter_space\":{\"learning_rate\":[\"choice\",[[0.001,0.005,0.009]]],\"first_layer\":[\"choice\",[[100,125,150]]],\"second_layer\":[\"choice\",[[30,60,90]]]},\"properties\":{\"rule\":\"Random\",\"seed\":null}}', '_aml_system_primary_metric_config': '{\"name\":\"sparse_categorical_accuracy\",\"goal\":\"maximize\"}', '_aml_system_platform_config': '{\"ServiceAddress\":\"https://eastus.api.azureml.ms\",\"SubscriptionId\":\"b3ae1c15-4fef-4362-8c3a-5d804cdeb18d\",\"ResourceGroupName\":\"AML-rg\",\"WorkspaceName\":\"ws01\",\"ExperimentName\":\"python_sdk2\",\"Definition\":{\"Configuration\":null,\"Attribution\":null,\"TelemetryValues\":null,\"Overrides\":{\"Script\":null,\"Command\":\"python train_experiment.py --data_folder ${{inputs.mnist_tf}}/train --learning_rate ${{search_space.learning_rate}} --first_layer ${{search_space.first_layer}} --second_layer ${{search_space.second_layer}}\",\"UseAbsolutePath\":true,\"Arguments\":[],\"SourceDirectoryDataStore\":null,\"Framework\":0,\"Target\":\"hypertest01\",\"DataReferences\":{},\"Data\":{\"mnist_tf\":{\"DataLocation\":{\"Dataset\":null,\"DataPath\":null,\"Uri\":{\"Path\":\"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/data/mnist_data/versions/1\",\"IsFile\":false},\"Type\":\"UriFolder\"},\"Mechanism\":\"Mount\",\"EnvironmentVariableName\":\"AZURE_ML_INPUT_mnist_tf\",\"PathOnCompute\":null,\"Overwrite\":false,\"Options\":{\"IsEvalMode\":\"False\",\"ReadWrite\":\"False\",\"ForceFolder\":\"False\"}}},\"InputAssets\":{\"mnist_tf\":{\"Asset\":{\"AssetId\":\"azureml://locations/eastus/workspaces/030b8dcf-1ffc-4245-9b2d-faabb1c4e31a/data/mnist_data/versions/1\",\"Type\":\"UriFolder\"},\"Mechanism\":\"Mount\",\"EnvironmentVariableName\":\"AZURE_ML_INPUT_mnist_tf\",\"PathOnCompute\":null,\"Overwrite\":false,\"Options\":{\"IsEvalMode\":\"False\",\"ReadWrite\":\"False\",\"ForceFolder\":\"False\"}}},\"OutputData\":{},\"Datacaches\":[],\"JobName\":null,\"MaxRunDurationSeconds\":null,\"NodeCount\":1,\"InstanceTypes\":[],\"Priority\":null,\"CredentialPassthrough\":false,\"Identity\":null,\"Environment\":{\"Name\":\"test-remote-cpu-env-for-logging\",\"Version\":\"1\",\"AssetId\":\"azureml://locations/eastus/workspaces/030b8dcf-1ffc-4245-9b2d-faabb1c4e31a/environments/test-remote-cpu-env-for-logging/versions/1\",\"AutoRebuild\":false,\"Python\":{\"InterpreterPath\":null,\"UserManagedDependencies\":false,\"CondaDependencies\":{\"channels\":[\"anaconda\",\"conda-forge\"],\"dependencies\":[\"python=3.8\",{\"pip\":[\"tensorflow==2.10.0\",\"mlflow\",\"azureml-mlflow\"]}],\"name\":\"project_environment\"},\"BaseCondaEnvironment\":null},\"EnvironmentVariables\":{},\"Docker\":{\"BaseImage\":\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\"Platform\":{\"Os\":\"Linux\",\"Architecture\":\"amd64\"},\"BaseDockerfile\":null,\"BaseImageRegistry\":null},\"Spark\":{\"Repositories\":[],\"Packages\":[],\"PrecachePackages\":true},\"InferencingStackVersion\":null},\"History\":{\"OutputCollection\":true,\"DirectoriesToWatch\":[\"logs\"],\"EnableMLflowTracking\":true},\"Spark\":{\"Configuration\":{}},\"ParallelTask\":{\"MaxRetriesPerWorker\":0,\"WorkerCountPerNode\":1,\"TerminalExitCodes\":null,\"Configuration\":{}},\"BatchAi\":{\"NodeCount\":0},\"AmlCompute\":{\"Name\":null,\"VmSize\":null,\"RetainCluster\":false,\"ClusterMaxNodeCount\":null},\"AISuperComputer\":{\"InstanceType\":\"D2\",\"FrameworkImage\":null,\"ImageVersion\":\"pytorch-1.7.0\",\"Location\":null,\"AISuperComputerStorageData\":null,\"Interactive\":false,\"ScalePolicy\":null,\"VirtualClusterArmId\":null,\"TensorboardLogDirectory\":null,\"SSHPublicKey\":null,\"SSHPublicKeys\":null,\"EnableAzmlInt\":true,\"Priority\":\"Medium\",\"SLATier\":\"Standard\",\"UserAlias\":null},\"KubernetesCompute\":{\"InstanceType\":null},\"Tensorflow\":{\"WorkerCount\":0,\"ParameterServerCount\":0},\"Mpi\":{\"ProcessCountPerNode\":0},\"PyTorch\":{\"CommunicationBackend\":null,\"ProcessCount\":null},\"Hdi\":{\"YarnDeployMode\":0},\"ContainerInstance\":{\"Region\":null,\"CpuCores\":2.0,\"MemoryGb\":3.5},\"ExposedPorts\":null,\"Docker\":{\"UseDocker\":true,\"SharedVolumes\":null,\"ShmSize\":null,\"Arguments\":null},\"Cmk8sCompute\":{\"Configuration\":{}},\"CommandReturnCodeConfig\":{\"ReturnCode\":0,\"SuccessfulReturnCodes\":[]},\"EnvironmentVariables\":{},\"ApplicationEndpoints\":{},\"Parameters\":[]},\"SnapshotId\":\"bb4a37de-df91-47b9-b690-02f37fc3d535\",\"Snapshots\":[],\"SourceCodeDataReference\":null,\"ParentRunId\":null,\"DataContainerId\":null,\"RunType\":null,\"DisplayName\":\"hyperdrive_test\",\"EnvironmentAssetId\":null,\"Properties\":{},\"Tags\":{},\"AggregatedArtifactPath\":null},\"ParentRunId\":\"neat_spoon_4r4xqk7mgd\"}', '_aml_system_resume_child_runs': 'null', '_aml_system_all_jobs_generated': 'false', '_aml_system_cancellation_requested': 'false'}, 'properties': {'primary_metric_config': '{\"name\":\"sparse_categorical_accuracy\",\"goal\":\"maximize\"}', 'resume_from': 'null', 'runTemplate': 'HyperDrive', 'azureml.runsource': 'hyperdrive', 'platform': 'AML', 'ContentSnapshotId': 'bb4a37de-df91-47b9-b690-02f37fc3d535', 'user_agent': 'managementfrontend/225e5b0e2332b018dcc960fa491a403660e897e7'}, 'id': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/neat_spoon_4r4xqk7mgd', 'Resource__source_path': None, 'base_path': '/home/tsmatsuz/python_sdk2', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd4bee57eb0>, 'serialize': <msrest.serialization.Serializer object at 0x7fd4bedea850>, 'sampling_algorithm': <azure.ai.ml.entities._job.sweep.sampling_algorithm.RandomSamplingAlgorithm object at 0x7fd4e821c760>, 'early_termination': None, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7fd4bee574c0>, 'search_space': {'learning_rate': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7fd4bee57ee0>, 'first_layer': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7fd4bee57fd0>, 'second_layer': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7fd4bee57190>}, 'objective': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.Objective object at 0x7fd4bedeac10>, 'display_name': 'hyperdrive_test', 'experiment_name': 'python_sdk2', 'compute': 'hypertest01', 'services': {'Studio': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7fd4bedead00>}, 'inputs': {'mnist_tf': {'type': 'uri_folder', 'path': 'azureml://locations/eastus/workspaces/030b8dcf-1ffc-4245-9b2d-faabb1c4e31a/data/mnist_data/versions/1', 'mode': 'ro_mount'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.neat_spoon_4r4xqk7mgd', 'mode': 'rw_mount'}}, 'trial': <azure.ai.ml.entities._job.parameterized_command.ParameterizedCommand object at 0x7fd4bee57e80>, 'identity': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then view logs and metrics in jobs on [Azure ML studio UI](https://ml.azure.com/).<br>\n",
    "(Select \"Trials\" tab.)\n",
    "\n",
    "![AML Hyperdrive Metrics](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20220225_Hyperdrive_Metrics.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting compute hypertest01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(2m 7s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_client.compute.begin_delete(\"hypertest01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
