{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise06 : Track Logs and Metrics\n",
    "\n",
    "Here we add logging capabilities in our source code, and check the collected logs and metrics.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MLClient\n",
    "\n",
    "Replace below's branket's string with your subscription id, resource group name, and AML workspace name.<br>\n",
    "(I note that creating ```MLClient``` will not connect to AML workspace, and the client initialization is lazy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DeviceCodeCredential, TokenCachePersistenceOptions\n",
    "\n",
    "# When you run on remote\n",
    "cache_opt = TokenCachePersistenceOptions(allow_unencrypted_storage=True)\n",
    "cred = DeviceCodeCredential(cache_persistence_options=cache_opt)\n",
    "\n",
    "# # When you run on Azure ML Notebook\n",
    "# from azure.identity import DefaultAzureCredential\n",
    "# cred = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=cred,\n",
    "    subscription_id=\"{SUBSCRIPTION ID}\",\n",
    "    resource_group_name=\"{RESOURCE GROUP NAME}\",\n",
    "    workspace_name=\"{AML WORKSPACE NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change your source code for experimentation logging\n",
    "\n",
    "By using the Azure Machine Learning CLI v2, **MLflow tracking URI and experiment's name are automatically set and redirects the logging from MLflow to your AML workspace**.<br>\n",
    "Therefore, change your source code in \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\" to track logs and metrics with MLflow as follows. (The lines commented by \"```##### Modified```\" are modified.)\n",
    "\n",
    "> Note : For details about MLflow and Azure ML integration, see [this repository](https://github.com/tsmatz/mlflow-azureml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train_experiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_experiment.py\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import mlflow ##### Modified\n",
    "mlflow.tensorflow.autolog() ##### Modified\n",
    "\n",
    "### You can also manually log as follows (Here we use autolog())\n",
    "# mlflow.log_params({\n",
    "#     'learning_rate': FLAGS.learning_rate,\n",
    "#     '1st_layer': FLAGS.first_layer,\n",
    "#     '2nd_layer': FLAGS.second_layer})\n",
    "# mlflow.log_metrics(\n",
    "#     {'training_accuracy': result_accuracy, 'training_loss': result_loss},\n",
    "#     step=result_step)\n",
    "\n",
    "# device test\n",
    "print(\"##### List of available GPU #####\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data_folder\",\n",
    "    type=str,\n",
    "    default=\"./data/train\",\n",
    "    help=\"Folder path for input data\")\n",
    "parser.add_argument(\n",
    "    \"--model_folder\",\n",
    "    type=str,\n",
    "    default=\"./outputs\",  # AML experiments outputs folder\n",
    "    help=\"Folder path for model output\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=\"0.001\",\n",
    "    help=\"Learning Rate\")\n",
    "parser.add_argument(\n",
    "    \"--first_layer\",\n",
    "    type=int,\n",
    "    default=\"128\",\n",
    "    help=\"Neuron number for the first hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--second_layer\",\n",
    "    type=int,\n",
    "    default=\"64\",\n",
    "    help=\"Neuron number for the second hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--epochs_num\",\n",
    "    type=int,\n",
    "    default=\"6\",\n",
    "    help=\"Number of epochs\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# build model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(FLAGS.first_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(FLAGS.second_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(FLAGS.learning_rate),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# run training\n",
    "train_data = tf.data.experimental.load(FLAGS.data_folder)\n",
    "model.fit(\n",
    "    train_data.shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=FLAGS.epochs_num\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_path = os.path.join(FLAGS.model_folder, \"mnist_tf_model\")\n",
    "model.save(model_path)\n",
    "print(\"current working directory : \", os.getcwd())\n",
    "print(\"model folder : \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on remote VM\n",
    "\n",
    "As you have learned in \"[Exercise04 : Train on Remote GPU Virtual Machine](./exercise04_train_remote.ipynb)\", run this script on AML remote compute.<br>\n",
    "(Here we use general purpose CPU machine, instead of GPU utilized machine.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create AML compute.\n",
    "\n",
    "> Note : By setting appropriate time duration in ```idle_time_before_scale_down``` parameter, you can prevent scaling-down when the training has finished. (Otherwise, it will scale down in 120 seconds after the training has finished, and the next training will slow to start because of cluster resizing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AY43LWJGG to authenticate.\n",
      "creating new.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(\"myvm02\")\n",
    "    print(\"found existing: \", compute_target.name)\n",
    "except Exception:\n",
    "    print(\"creating new.\")\n",
    "    compute_target = AmlCompute(\n",
    "        name=\"myvm02\",\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_D2_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=1,\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    compute_target = ml_client.begin_create_or_update(compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create custom environment.<br>\n",
    "As I have mentioned above, MLflow tracking is configured in AML CLI v2. For MLflow logging, ```mlflow``` and ```azureml-mlflow``` packages should be installed on the environment as follows.<br>\n",
    "Here I have created own environment, but you can also use AML built-in environment (curated environment), in which MLflow is already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 06_conda_pydata_for_logging.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 06_conda_pydata_for_logging.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "- python=3.8\n",
    "- pip:\n",
    "  - tensorflow==2.10.0\n",
    "  - mlflow\n",
    "  - azureml-mlflow\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "myenv = Environment(\n",
    "    name=\"test-remote-cpu-env-for-logging\",\n",
    "    description=\"This is example\",\n",
    "    conda_file=\"06_conda_pydata_for_logging.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    ")\n",
    "myenv = ml_client.environments.create_or_update(myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [AML Studio UI](https://ml.azure.com/) and click \"Environments\". Next, click \"Custom environments\" tab and select the above environment.<br>\n",
    "Please wait until the environment image build status is succeeded.\n",
    "\n",
    "![Environment status](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20221220_Environment_Status.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run script on above custom environment, in which ```mlflow``` and ```azureml-mlflow``` are already installed.\n",
    "\n",
    "> Note : In this example, I also use the registered data asset named ```mnist_data``` to mount in your compute target. Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script (0.01 MBs): 100%|████████████████████████████████████████| 6402/6402 [00:00<00:00, 134283.17it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command, Input\n",
    "\n",
    "# create the command\n",
    "job = command(\n",
    "    code=\"./script\",\n",
    "    command=\"python train_experiment.py --data_folder ${{inputs.mnist_tf}}/train\",\n",
    "    inputs={\n",
    "        \"mnist_tf\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"mnist_data@latest\",\n",
    "        ),\n",
    "    },\n",
    "    environment=\"test-remote-cpu-env-for-logging@latest\",\n",
    "    compute=\"myvm02\",\n",
    "    display_name=\"tf_remote_experiment02\",\n",
    "    experiment_name=\"tf_remote_experiment02\",\n",
    "    description=\"This is example\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See logs in AML Studio UI\n",
    "\n",
    "Go to [AML Studio UI](https://ml.azure.com/).<br>\n",
    "Click \"Jobs\" and select \"tf_remote_experiment02\". You can then see the recorded metrics as follows.\n",
    "\n",
    "![AML Experiment Metrics](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20220225_Experiment_Metrics.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting compute myvm02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(5m 3s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_client.compute.begin_delete(\"myvm02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
