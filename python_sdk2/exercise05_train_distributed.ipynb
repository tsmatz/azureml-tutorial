{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise05 : Distributed Training with Curated Environments\n",
    "\n",
    "Here we change our sample (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") for distributed training using multiple machines in Azure Machine Learning.\n",
    "\n",
    "In this exercise, we use Horovod framework in AML built-in environment. (As you saw in previous [Exercise04](./exercise04_train_remote.ipynb), you can also run distributed training with manually-configured custom environment.)\n",
    "\n",
    "In this example, we use multiple machines, but you can also configure Horovod distributed training to run on multiple devices (such as, multiple GPUs).\n",
    "\n",
    "> Note : In this example, I manually configure MPI distribution, but you can also use built-in ```azure.ai.ml.TensorFlowDistribution``` for TensorFlow distribution.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MLClient\n",
    "\n",
    "Replace below's branket's string with your subscription id, resource group name, and AML workspace name.<br>\n",
    "(I note that creating ```MLClient``` will not connect to AML workspace, and the client initialization is lazy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DeviceCodeCredential\n",
    "\n",
    "# When you run on remote\n",
    "cred = DeviceCodeCredential()\n",
    "\n",
    "# # When you run on Azure ML Notebook\n",
    "# from azure.identity import DefaultAzureCredential\n",
    "# cred = DefaultAzureCredential()\n",
    "\n",
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=cred,\n",
    "    subscription_id=\"{SUBSCRIPTION ID}\",\n",
    "    resource_group_name=\"{RESOURCE GROUP NAME}\",\n",
    "    workspace_name=\"{AML WORKSPACE NAME}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change our original source code ```train.py``` (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") as follows. (The lines commented \"##### modified\" is modified lines.)<br>\n",
    "This source code will then be saved as ```./script/train_horovod.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train_horovod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_horovod.py\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import horovod.tensorflow.keras as hvd ##### modified\n",
    "\n",
    "# device test\n",
    "print(\"##### List of available GPU #####\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data_folder\",\n",
    "    type=str,\n",
    "    default=\"./data/train\",\n",
    "    help=\"Folder path for input data\")\n",
    "parser.add_argument(\n",
    "    \"--model_folder\",\n",
    "    type=str,\n",
    "    default=\"./outputs\",  # AML experiments outputs folder\n",
    "    help=\"Folder path for model output\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=\"0.001\",\n",
    "    help=\"Learning Rate\")\n",
    "parser.add_argument(\n",
    "    \"--first_layer\",\n",
    "    type=int,\n",
    "    default=\"128\",\n",
    "    help=\"Neuron number for the first hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--second_layer\",\n",
    "    type=int,\n",
    "    default=\"64\",\n",
    "    help=\"Neuron number for the second hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--epochs_num\",\n",
    "    type=int,\n",
    "    default=\"6\",\n",
    "    help=\"Number of epochs\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "hvd.init() ##### modified\n",
    "\n",
    "# Horovod config output\n",
    "print(\"##### Horovod config #####\")\n",
    "print(\"Size {}\".format(hvd.size()))\n",
    "print(\"Rank {}\".format(hvd.rank()))\n",
    "\n",
    "# build model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(FLAGS.first_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(FLAGS.second_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(FLAGS.learning_rate)\n",
    "opt = hvd.DistributedOptimizer(opt) ##### modified\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# run training\n",
    "train_data = tf.data.experimental.load(FLAGS.data_folder)\n",
    "model.fit(\n",
    "    train_data.shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE),\n",
    "    callbacks=[hvd.callbacks.BroadcastGlobalVariablesCallback(0)],  ##### modified\n",
    "    epochs=FLAGS.epochs_num\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "if hvd.rank() == 0 : ##### modified\n",
    "    model_path = os.path.join(FLAGS.model_folder, \"mnist_tf_model\")\n",
    "    model.save(model_path)\n",
    "    print(\"current working directory : \", os.getcwd())\n",
    "    print(\"model folder : \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on multiple machines (Horovod)\n",
    "\n",
    "Now let's start to integrate with AML and automate distributed training on remote virtual machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Create multiple virtual machines (cluster)\n",
    "\n",
    "Create your new AML compute for distributed clusters. By enabling auto-scaling from 0 to 3, you can scale distributed workloads and also save money (all nodes are terminated) if it's inactive.\n",
    "\n",
    "> Note : By setting appropriate time duration in ```idle_time_before_scale_down``` parameter, you can prevent scaling-down when the training has finished. (Otherwise, it will scale down in 120 seconds after the training has finished, and the next training will slow to start because of cluster resizing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FKC6KGBWX to authenticate.\n",
      "creating new.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "try:\n",
    "    compute_target = ml_client.compute.get(\"mycluster01\")\n",
    "    print(\"found existing: \", compute_target.name)\n",
    "except Exception:\n",
    "    print(\"creating new.\")\n",
    "    compute_target = AmlCompute(\n",
    "        name=\"mycluster01\",\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_D2_v2\",\n",
    "        min_instances=0,\n",
    "        max_instances=3,\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    compute_target = ml_client.begin_create_or_update(compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Submit a training job\n",
    "\n",
    "Submit a training job with above compute.<br>\n",
    "In this training, this job will be distributed on 3 node.\n",
    "\n",
    "Horovod (with TensorFlow) 0.23.0 is installed in this built-in image, ```AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu```.\n",
    "\n",
    "In this example, I also use the registered data asset named ```mnist_data``` to mount in your compute target. (Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation.)\n",
    "\n",
    "> Note : In this example, I have used built-in GPU environment (```AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu```) on CPU cluster. If GPU is not available, it will correctly run on CPU.<br>\n",
    "> When you prefer CPU image, you can also create and configure your own image. (See [Exercise04](./exercise04_train_remote.ipynb).)\n",
    "\n",
    "See the progress and results in job view on [AML Studio](https://ml.azure.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script (0.0 MBs): 100%|██████████████████████████████████████████| 4135/4135 [00:00<00:00, 92418.53it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command, Input, MpiDistribution\n",
    "from azure.ai.ml.entities import JobResourceConfiguration\n",
    "\n",
    "# create the command\n",
    "job = command(\n",
    "    code=\"./script\",\n",
    "    command=\"python train_horovod.py --data_folder ${{inputs.mnist_tf}}/train\",\n",
    "    inputs={\n",
    "        \"mnist_tf\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"mnist_data@latest\",\n",
    "        ),\n",
    "    },\n",
    "    environment=\"AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu@latest\",\n",
    "    compute=\"mycluster01\",\n",
    "    resources=JobResourceConfiguration(instance_count=3),\n",
    "    distribution=MpiDistribution(process_count_per_instance=1),\n",
    "    display_name=\"tf_distribued\",\n",
    "    experiment_name=\"tf_distribued\",\n",
    "    description=\"This is example\",\n",
    ")\n",
    "\n",
    "# submit the command\n",
    "returned_job = ml_client.create_or_update(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please wait until the job is completed.\n",
    "\n",
    "You can see current status (progress) with [AML studio UI](https://ml.azure.com/) (see \"Jobs\" pane) or with the following CLI command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>tf_distribued</td><td>ivory_map_2092zc6s7t</td><td>command</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/ivory_map_2092zc6s7t?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AML-rg/workspaces/ws01&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "Command({'parameters': {}, 'init': False, 'type': 'command', 'status': 'Completed', 'log_files': None, 'name': 'ivory_map_2092zc6s7t', 'description': 'This is example', 'tags': {'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":0}', 'mlflow.source.type': 'JOB', 'mlflow.source.name': None}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', 'ContentSnapshotId': '62e7f070-e071-4cd9-80f3-5afeec842d69', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'id': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/ivory_map_2092zc6s7t', 'Resource__source_path': None, 'base_path': '/home/tsmatsuz/python_sdk2', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fb8bf3470d0>, 'serialize': <msrest.serialization.Serializer object at 0x7fb8bd33c3a0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'tf_distribued', 'experiment_name': 'tf_distribued', 'compute': 'mycluster01', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7fb8bd473df0>, 'Studio': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7fb8bd473dc0>}, 'job_inputs': {'mnist_tf': {'type': 'uri_folder', 'path': 'mnist_data:1', 'mode': 'ro_mount'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.ivory_map_2092zc6s7t', 'mode': 'rw_mount'}}, 'inputs': {'mnist_tf': <azure.ai.ml.entities._job.pipeline._io.PipelineInputBase object at 0x7fb8bd493f70>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.PipelineOutputBase object at 0x7fb8bd33c430>}, 'component': CommandComponent({'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'name': 'ivory_map_2092zc6s7t', 'description': 'This is example', 'tags': {'_aml_system_ComputeTargetStatus': '{\"AllocationState\":\"steady\",\"PreparingNodeCount\":0,\"RunningNodeCount\":0,\"CurrentNodeCount\":0}', 'mlflow.source.type': 'JOB', 'mlflow.source.name': None}, 'properties': {}, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fb8bf3470d0>, 'serialize': <msrest.serialization.Serializer object at 0x7fb8eb71e5e0>, 'command': 'python train_horovod.py --data_folder ${{inputs.mnist_tf}}/train', 'code': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/b4007170-4274-428b-871e-4b7bd39a761f/versions/1', 'environment_variables': {}, 'environment': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/environments/AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu/versions/23', 'distribution': <azure.ai.ml.entities._job.distribution.MpiDistribution object at 0x7fb8beab73d0>, 'resources': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'tf_distribued', 'is_deterministic': True, 'inputs': {'mnist_tf': {'type': 'uri_folder', 'path': '/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/data/mnist_data/versions/1', 'mode': 'ro_mount'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.ivory_map_2092zc6s7t', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Completed', 'parameters': {}}, 'func': <function [component] tf_distribued at 0x7fb8bd48a3a0>}), 'kwargs': {'services': {'Tracking': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7fb8bd473df0>, 'Studio': <azure.ai.ml._restclient.v2022_06_01_preview.models._models_py3.JobService object at 0x7fb8bd473dc0>}, 'status': 'Completed', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fb8bf3470d0>}, 'instance_id': '1734e42f-d395-427c-8d8a-e01b22d59408', 'source': 'BUILDER', 'limits': None, 'identity': None, 'distribution': <azure.ai.ml.entities._job.distribution.MpiDistribution object at 0x7fb8beab73d0>, 'environment_variables': {}, 'environment': 'AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu:23', 'resources': {'instance_count': 3, 'shm_size': '2g', 'properties': {}}, 'swept': False})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.jobs.get(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting compute mycluster01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "(0m 36s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_client.compute.begin_delete(\"mycluster01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
