{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise05 : Distributed Training with Curated Environments\n",
    "\n",
    "Here we change our sample (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") for distributed training using multiple machines in Azure Machine Learning.\n",
    "\n",
    "In this exercise, we use Horovod framework in AML built-in environment. (As you saw in previous [Exercise04](./exercise04_train_remote.ipynb), you can also run distributed training with manually-configured custom environment.)\n",
    "\n",
    "In this example, we use multiple machines, but you can also configure Horovod distributed training to run on multiple devices (such as, multiple GPUs).\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable's Setting\n",
    "\n",
    "Replace below's branket's string and set the required variables.\n",
    "\n",
    "> Note : By the following ```az configure --defaults```, you can skip setting for ```--resource-group``` and ```--workspace-name``` options in each ```az ml``` command.<br>\n",
    "> ```az configure --defaults group=$resource_group workspace=$aml_workspace```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML-RESOURCE-GROUP-NAME}\"\n",
    "my_workspace = \"{AML-WORSPACE-NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training script as file (train.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change our original source code ```train.py``` (see \"[Exercise03 : Just Train in Your Working Machine](./exercise03_train_simple.ipynb)\") as follows. (The lines commented \"##### modified\" is modified lines.)<br>\n",
    "This source code will then be saved as ```./script/train_horovod.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script/train_horovod.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_horovod.py\n",
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import horovod.tensorflow.keras as hvd ##### modified\n",
    "\n",
    "# device test\n",
    "print(\"##### List of available GPU #####\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--data_folder\",\n",
    "    type=str,\n",
    "    default=\"./data/train\",\n",
    "    help=\"Folder path for input data\")\n",
    "parser.add_argument(\n",
    "    \"--model_folder\",\n",
    "    type=str,\n",
    "    default=\"./outputs\",  # AML experiments outputs folder\n",
    "    help=\"Folder path for model output\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\",\n",
    "    type=float,\n",
    "    default=\"0.001\",\n",
    "    help=\"Learning Rate\")\n",
    "parser.add_argument(\n",
    "    \"--first_layer\",\n",
    "    type=int,\n",
    "    default=\"128\",\n",
    "    help=\"Neuron number for the first hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--second_layer\",\n",
    "    type=int,\n",
    "    default=\"64\",\n",
    "    help=\"Neuron number for the second hidden layer\")\n",
    "parser.add_argument(\n",
    "    \"--epochs_num\",\n",
    "    type=int,\n",
    "    default=\"6\",\n",
    "    help=\"Number of epochs\")\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "hvd.init() ##### modified\n",
    "\n",
    "# Horovod config output\n",
    "print(\"##### Horovod config #####\")\n",
    "print(\"Size {}\".format(hvd.size()))\n",
    "print(\"Rank {}\".format(hvd.rank()))\n",
    "\n",
    "# build model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(FLAGS.first_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(FLAGS.second_layer, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(FLAGS.learning_rate)\n",
    "opt = hvd.DistributedOptimizer(opt) ##### modified\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# run training\n",
    "train_data = tf.data.experimental.load(FLAGS.data_folder)\n",
    "model.fit(\n",
    "    train_data.shuffle(1000).batch(128).prefetch(tf.data.AUTOTUNE),\n",
    "    callbacks=[hvd.callbacks.BroadcastGlobalVariablesCallback(0)],  ##### modified\n",
    "    epochs=FLAGS.epochs_num\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "if hvd.rank() == 0 : ##### modified\n",
    "    model_path = os.path.join(FLAGS.model_folder, \"mnist_tf_model\")\n",
    "    model.save(model_path)\n",
    "    print(\"current working directory : \", os.getcwd())\n",
    "    print(\"model folder : \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on multiple machines (Horovod)\n",
    "\n",
    "Now let's start to integrate with AML and automate distributed training on remote virtual machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Create multiple virtual machines (cluster)\n",
    "\n",
    "Create your new AML compute for distributed clusters. By enabling auto-scaling from 0 to 3, you can scale distributed workloads and also save money (all nodes are terminated) if it's inactive.\n",
    "\n",
    "> Note : By setting appropriate time duration in ```--idle-time-before-scale-down``` option, you can prevent scaling-down when the training has finished. (Otherwise, it will scale down in 120 seconds after the training has finished, and the next training will slow to start because of cluster resizing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K{\\ Finished ..\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/mycluster01\",\n",
      "  \"idle_time_before_scale_down\": 120,\n",
      "  \"location\": \"eastus\",\n",
      "  \"max_instances\": 3,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"mycluster01\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"rg-AML\",\n",
      "  \"size\": \"STANDARD_D2_V2\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name mycluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 3 \\\n",
    "  --size Standard_D2_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Submit a training job\n",
    "\n",
    "Submit a training job with above compute.<br>\n",
    "In this training, this job will be distributed on 3 node.\n",
    "\n",
    "Horovod (with TensorFlow) 0.23.0 is installed in this built-in image, ```AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu```.\n",
    "\n",
    "In this example, I also use the registered data asset named ```mnist_data``` to mount in your compute target. (Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation.)\n",
    "\n",
    "> Note : In this example, I have used built-in GPU environment (```AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu```) on CPU cluster. If GPU is not available, it will correctly run on CPU.<br>\n",
    "> When you prefer CPU image, you can also create and configure your own image. (See [Exercise04](./exercise04_train_remote.ipynb).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 05_mnist_distributed_job.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 05_mnist_distributed_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "code: script\n",
    "command: >-\n",
    "  python train_horovod.py\n",
    "  --data_folder ${{inputs.mnist_tf}}/train\n",
    "inputs:\n",
    "  mnist_tf:\n",
    "    type: uri_folder\n",
    "    path: azureml:mnist_data@latest\n",
    "environment: azureml:AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu@latest\n",
    "compute: azureml:mycluster01\n",
    "resources:\n",
    "  instance_count: 3\n",
    "distribution:\n",
    "  type: mpi\n",
    "  process_count_per_instance: 1\n",
    "display_name: tf_distribued\n",
    "experiment_name: tf_distribued\n",
    "description: This is example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's submit a job with AML CLI.<br>\n",
    "See the progress and results in job view on [AML Studio](https://ml.azure.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script (0.01 MBs): 100%|██████| 6861/6861 [00:00<00:00, 149916.75it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"code\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/7c6cb5a7-40e7-4e84-9627-a794d3e2e9a5/versions/1\",\n",
      "  \"command\": \"python train_horovod.py --data_folder ${{inputs.mnist_tf}}/train\",\n",
      "  \"compute\": \"azureml:mycluster01\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-10-04T05:29:36.109492+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"This is example\",\n",
      "  \"display_name\": \"tf_distribued\",\n",
      "  \"distribution\": {\n",
      "    \"process_count_per_instance\": 1,\n",
      "    \"type\": \"mpi\"\n",
      "  },\n",
      "  \"environment\": \"azureml:AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu:23\",\n",
      "  \"environment_variables\": {},\n",
      "  \"experiment_name\": \"tf_distribued\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/nice_stick_z0qlkx99sm\",\n",
      "  \"inputs\": {\n",
      "    \"mnist_tf\": {\n",
      "      \"mode\": \"ro_mount\",\n",
      "      \"path\": \"azureml:mnist_data:1\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"name\": \"nice_stick_z0qlkx99sm\",\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.nice_stick_z0qlkx99sm\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"parameters\": {},\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"13c77b1f-75ca-4d82-9086-042c2989ecc5\",\n",
      "    \"_azureml.ComputeTargetType\": \"amlctrain\"\n",
      "  },\n",
      "  \"resourceGroup\": \"rg-AML\",\n",
      "  \"resources\": {\n",
      "    \"instance_count\": 3,\n",
      "    \"properties\": {},\n",
      "    \"shm_size\": \"2g\"\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/nice_stick_z0qlkx99sm?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    },\n",
      "    \"Tracking\": {\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01?\",\n",
      "      \"job_service_type\": \"Tracking\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Starting\",\n",
      "  \"tags\": {},\n",
      "  \"type\": \"command\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file 05_mnist_distributed_job.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can show the progress and result with the following CLI command.<br>\n",
    "(**Replace ```nice_stick_z0qlkx99sm``` with your generated job name**. For getting job name, see above output.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"nice_stick_z0qlkx99sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"code\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/7c6cb5a7-40e7-4e84-9627-a794d3e2e9a5/versions/1\",\r\n",
      "  \"command\": \"python train_horovod.py --data_folder ${{inputs.mnist_tf}}/train\",\r\n",
      "  \"compute\": \"azureml:mycluster01\",\r\n",
      "  \"creation_context\": {\r\n",
      "    \"created_at\": \"2022-10-04T05:29:36.109492+00:00\",\r\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\r\n",
      "    \"created_by_type\": \"User\"\r\n",
      "  },\r\n",
      "  \"description\": \"This is example\",\r\n",
      "  \"display_name\": \"tf_distribued\",\r\n",
      "  \"distribution\": {\r\n",
      "    \"process_count_per_instance\": 1,\r\n",
      "    \"type\": \"mpi\"\r\n",
      "  },\r\n",
      "  \"environment\": \"azureml:AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu:23\",\r\n",
      "  \"environment_variables\": {},\r\n",
      "  \"experiment_name\": \"tf_distribued\",\r\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/nice_stick_z0qlkx99sm\",\r\n",
      "  \"inputs\": {\r\n",
      "    \"mnist_tf\": {\r\n",
      "      \"mode\": \"ro_mount\",\r\n",
      "      \"path\": \"azureml:mnist_data:1\",\r\n",
      "      \"type\": \"uri_folder\"\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"name\": \"nice_stick_z0qlkx99sm\",\r\n",
      "  \"outputs\": {\r\n",
      "    \"default\": {\r\n",
      "      \"mode\": \"rw_mount\",\r\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.nice_stick_z0qlkx99sm\",\r\n",
      "      \"type\": \"uri_folder\"\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"parameters\": {},\r\n",
      "  \"properties\": {\r\n",
      "    \"ContentSnapshotId\": \"13c77b1f-75ca-4d82-9086-042c2989ecc5\",\r\n",
      "    \"ProcessInfoFile\": \"azureml-logs/process_info.json\",\r\n",
      "    \"ProcessStatusFile\": \"azureml-logs/process_status.json\",\r\n",
      "    \"_azureml.ComputeTargetType\": \"amlctrain\"\r\n",
      "  },\r\n",
      "  \"resourceGroup\": \"rg-AML\",\r\n",
      "  \"resources\": {\r\n",
      "    \"instance_count\": 3,\r\n",
      "    \"properties\": {},\r\n",
      "    \"shm_size\": \"2g\"\r\n",
      "  },\r\n",
      "  \"services\": {\r\n",
      "    \"Studio\": {\r\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/nice_stick_z0qlkx99sm?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/rg-AML/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\r\n",
      "      \"job_service_type\": \"Studio\"\r\n",
      "    },\r\n",
      "    \"Tracking\": {\r\n",
      "      \"endpoint\": \"azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/rg-AML/providers/Microsoft.MachineLearningServices/workspaces/ws01?\",\r\n",
      "      \"job_service_type\": \"Tracking\"\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"status\": \"Completed\",\r\n",
      "  \"tags\": {\r\n",
      "    \"mlflow.source.name\": null,\r\n",
      "    \"mlflow.source.type\": \"JOB\"\r\n",
      "  },\r\n",
      "  \"type\": \"command\"\r\n",
      "}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job show --name $job_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Download results and check\n",
    "\n",
    "Check the generated model in local computer.\n",
    "\n",
    "By running the following ```az ml job download``` command, the logs and outputs are downloaded in local computer.<br>\n",
    "The logs are saved in ```artifacts/logs``` and outputs are in ```artifacts/outputs```.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.nice_stick_z0qlkx99sm to /home/tsmatsuz/cli_yaml/artifacts\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job download --name $job_name \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the downloaded result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 05:58:44.192520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 05:58:44.334760: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-04 05:58:44.334790: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-04 05:58:44.371487: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-04 05:58:45.203129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-04 05:58:45.203264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-04 05:58:45.203279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-04 05:58:45.998955: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-04 05:58:45.998996: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-04 05:58:45.999038: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (client1004): /proc/driver/nvidia/version does not exist\n",
      "2022-10-04 05:58:45.999253: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 7, True 7\n",
      "Predicted 1, True 2\n",
      "Predicted 1, True 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "test_data = tf.data.Dataset.load(\"./data/test\")\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"./artifacts/outputs/mnist_tf_model\")\n",
    "for image, true_value in test_data.take(3):\n",
    "    pred_output = loaded_model(tf.expand_dims(image, axis=0))\n",
    "    pred_value = tf.math.argmax(pred_output, axis=-1).numpy().item()\n",
    "    print(\"Predicted {}, True {}\".format(pred_value, true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting compute mycluster01 \n",
      ".......Done.\n",
      "(0m 36s)\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute delete --name mycluster01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
