{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise07 : Hyperparameter Tuning (Sweep Job)\n",
    "\n",
    "AML provides framework-independent hyperparameter tuning capability.<br>\n",
    "You can quickly search optimal parameters with scaled training workloads. This capability also works with metrics in AML logging.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable's Setting\n",
    "\n",
    "Replace below's branket's string and set the required variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML-RESOURCE-GROUP-NAME}\"\n",
    "my_workspace = \"{AML-WORSPACE-NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training code\n",
    "\n",
    "First, you must save your training code.    \n",
    "Here I should use the source code in \"[Exercise06 : Track Logs and Metrics](./exercise06_experimentation.ipynb)\", which sends logs into AML run history. (The metrics will be tracked in hyper-parameter tuning (sweep) job.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save source code as ```./script/train_expriment.py```.<br>\n",
    "This source code is the exact same source code as one in \"[Exercise06 : Track Logs and Metrics](./exercise06_experimentation.ipynb)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/train_experiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_experiment.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import mlflow\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        # Ask for accuracy and loss in each steps\n",
    "        class _CustomLoggingHook(tf.train.SessionRunHook):\n",
    "            def before_run(self, run_context):\n",
    "                return tf.train.SessionRunArgs([accuracy[1], loss, global_step])\n",
    "            def after_run(self, run_context, run_values):\n",
    "                result_accuracy, result_loss, result_step = run_values.results\n",
    "                if result_step % 10 == 0 :\n",
    "                    mlflow.log_metrics(\n",
    "                        {'training_accuracy': result_accuracy, 'training_loss': result_loss},\n",
    "                        step=result_step)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            training_chief_hooks=[_CustomLoggingHook()],\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.estimator.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "eval_res = tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)\n",
    "\n",
    "# send logs to AML\n",
    "mlflow.log_params({\n",
    "    'learning_rate': FLAGS.learning_rate,\n",
    "    '1st_layer': FLAGS.first_layer,\n",
    "    '2nd_layer': FLAGS.second_layer})\n",
    "mlflow.log_metrics({\n",
    "    'final_accuracy': eval_res[0]['accuracy'],\n",
    "    'final_loss': eval_res[0]['loss']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML compute\n",
    "\n",
    "Create AML compute pool for computing environment.<br>\n",
    "Here I create a cluster with max 4 instances to scale sweep job.\n",
    "\n",
    "> Note : By setting appropriate time duration in ```--idle-time-before-scale-down``` option, you can prevent scaling-down when the training has finished. (Otherwise, it will scale down in 120 seconds after the training has finished, and the next training will slow to start because of cluster resizing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/hypertest01\",\n",
      "  \"idle_time_before_scale_down\": 120,\n",
      "  \"location\": \"eastus\",\n",
      "  \"max_instances\": 4,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"hypertest01\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"size\": \"STANDARD_D2_V2\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name hypertest01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 4 \\\n",
    "  --size Standard_D2_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML environment\n",
    "\n",
    "As I have mentioned in \"[Exercise06 : Track Logs and Metrics](./exercise06_experimentation.ipynb)\", we should use an environment with ```mlflow``` and ```azureml-mlflow``` installed.\n",
    "\n",
    "**If you have already created custom environment in [Exercise06](./exercise06_experimentation.ipynb), you don't need to run the following command.** (Because this custom environment already exists.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 06_conda_pydata_for_logging.yml\n",
    "name: project_environment\n",
    "dependencies:\n",
    "- python=3.6\n",
    "- pip:\n",
    "  - tensorflow-gpu==1.15\n",
    "  - mlflow\n",
    "  - azureml-mlflow\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 06_env_register.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/environment.schema.json\n",
    "name: test-remote-cpu-env-for-logging\n",
    "image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
    "conda_file: 06_conda_pydata_for_logging.yml\n",
    "description: This is example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az ml environment create --file 06_env_register.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a job with hyper-parameter's search\n",
    "\n",
    "Now submit a job, in which multiple trainings will run depending on different hyper-parameters.<br>\n",
    "In this example, we monitor training accuracy depending on 3 arguments - ```--learning_rate```, ```--first_layer```, and ```--second_layer```. Each arguments can have 3 different values (and then total 27 trials can be run), but here I set maximum 20 trials to run, in which the values of arguments are randomly picked up.\n",
    "<br>These trials will be parallelized on above 4 node to speed up.\n",
    "\n",
    "For ```sampling_algorithm```, you can use ```grid```, ```random```, and ```bayesian```.<br>\n",
    "You can also specify an early termnination policy (```early_termination```), in which the training will terminate if the primary metric falls outside of some threshold. (Here we don't apply early termination.)\n",
    "\n",
    "> Note : In this example, I also use the registered data asset  (train.tfrecords, test.tfrecords) named ```mnist_tfrecords_data``` to mount in your compute target. Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 07_hyperparam_job.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 07_hyperparam_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/sweepJob.schema.json\n",
    "type: sweep\n",
    "trial:\n",
    "  code: script\n",
    "  command: >-\n",
    "    python train_experiment.py\n",
    "    --data_folder ${{inputs.mnist_tf}}\n",
    "    --learning_rate ${{search_space.learning_rate}}\n",
    "    --first_layer ${{search_space.first_layer}}\n",
    "    --second_layer ${{search_space.second_layer}}\n",
    "  environment: azureml:test-remote-cpu-env-for-logging@latest\n",
    "inputs:\n",
    "  mnist_tf:\n",
    "    type: uri_folder\n",
    "    path: azureml:mnist_tfrecords_data@latest\n",
    "compute: azureml:hypertest01\n",
    "sampling_algorithm: random\n",
    "search_space:\n",
    "  learning_rate:\n",
    "    type: choice\n",
    "    values: [0.01, 0.05, 0.9]\n",
    "  first_layer:\n",
    "    type: choice\n",
    "    values: [100, 125, 150]\n",
    "  second_layer:\n",
    "    type: choice\n",
    "    values: [30, 60, 90]\n",
    "objective:\n",
    "  goal: maximize\n",
    "  primary_metric: training_accuracy\n",
    "limits:\n",
    "  max_total_trials: 20\n",
    "  max_concurrent_trials: 4\n",
    "display_name: hyperdrive_test\n",
    "experiment_name: hyperdrive_test\n",
    "description: This is example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading script (0.02 MBs): 100%|████| 22737/22737 [00:00<00:00, 614732.36it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"compute\": \"azureml:hypertest01\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-06-07T02:59:55.460612+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"This is example\",\n",
      "  \"display_name\": \"hyperdrive_test\",\n",
      "  \"experiment_name\": \"hyperdrive_test\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/quiet_boat_r3cvz6k5c3\",\n",
      "  \"inputs\": {\n",
      "    \"mnist_tf\": {\n",
      "      \"mode\": \"ro_mount\",\n",
      "      \"path\": \"azureml://locations/eastus/workspaces/e3065a8e-03f5-431f-a3d9-976175f54379/data/mnist_tfrecords_data/versions/1\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"limits\": {\n",
      "    \"max_concurrent_trials\": 4,\n",
      "    \"max_total_trials\": 20,\n",
      "    \"timeout\": 5184000\n",
      "  },\n",
      "  \"name\": \"quiet_boat_r3cvz6k5c3\",\n",
      "  \"objective\": {\n",
      "    \"goal\": \"maximize\",\n",
      "    \"primary_metric\": \"training_accuracy\"\n",
      "  },\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"mode\": \"rw_mount\",\n",
      "      \"path\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.quiet_boat_r3cvz6k5c3\",\n",
      "      \"type\": \"uri_folder\"\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"d61b3e31-da5b-4bde-a4d8-ed4be31b4ba9\",\n",
      "    \"azureml.runsource\": \"hyperdrive\",\n",
      "    \"platform\": \"AML\",\n",
      "    \"primary_metric_config\": \"{\\\"name\\\": \\\"training_accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\",\n",
      "    \"resume_from\": \"null\",\n",
      "    \"runTemplate\": \"HyperDrive\",\n",
      "    \"user_agent\": \"managementfrontend/72ea92f7a1317aed7a379cb4bac22ba1db9add76\"\n",
      "  },\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"sampling_algorithm\": {\n",
      "    \"rule\": \"random\",\n",
      "    \"type\": \"random\"\n",
      "  },\n",
      "  \"search_space\": {\n",
      "    \"first_layer\": {\n",
      "      \"type\": \"choice\",\n",
      "      \"values\": [\n",
      "        100,\n",
      "        125,\n",
      "        150\n",
      "      ]\n",
      "    },\n",
      "    \"learning_rate\": {\n",
      "      \"type\": \"choice\",\n",
      "      \"values\": [\n",
      "        0.01,\n",
      "        0.05,\n",
      "        0.9\n",
      "      ]\n",
      "    },\n",
      "    \"second_layer\": {\n",
      "      \"type\": \"choice\",\n",
      "      \"values\": [\n",
      "        30,\n",
      "        60,\n",
      "        90\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/quiet_boat_r3cvz6k5c3?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AML-rg/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Running\",\n",
      "  \"tags\": {\n",
      "    \"_aml_system_all_jobs_generated\": \"false\",\n",
      "    \"_aml_system_cancellation_requested\": \"false\",\n",
      "    \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"properties\\\": {\\\"rule\\\": \\\"Random\\\", \\\"seed\\\": null}, \\\"parameter_space\\\": {\\\"learning_rate\\\": [\\\"choice\\\", [[0.01, 0.05, 0.9]]], \\\"first_layer\\\": [\\\"choice\\\", [[100, 125, 150]]], \\\"second_layer\\\": [\\\"choice\\\", [[30, 60, 90]]]}}\",\n",
      "    \"_aml_system_max_concurrent_jobs\": \"4\",\n",
      "    \"_aml_system_max_duration_minutes\": \"86400\",\n",
      "    \"_aml_system_max_total_jobs\": \"20\",\n",
      "    \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://eastus.api.azureml.ms\\\", \\\"SubscriptionId\\\": \\\"b3ae1c15-4fef-4362-8c3a-5d804cdeb18d\\\", \\\"ResourceGroupName\\\": \\\"AML-rg\\\", \\\"WorkspaceName\\\": \\\"ws01\\\", \\\"ExperimentName\\\": \\\"hyperdrive_test\\\", \\\"Definition\\\": {\\\"Configuration\\\": null, \\\"Attribution\\\": null, \\\"TelemetryValues\\\": null, \\\"Overrides\\\": {\\\"Script\\\": null, \\\"Command\\\": \\\"python train_experiment.py --data_folder ${{inputs.mnist_tf}} --learning_rate ${{search_space.learning_rate}} --first_layer ${{search_space.first_layer}} --second_layer ${{search_space.second_layer}}\\\", \\\"UseAbsolutePath\\\": true, \\\"Arguments\\\": [], \\\"SourceDirectoryDataStore\\\": null, \\\"Framework\\\": 0, \\\"Target\\\": \\\"hypertest01\\\", \\\"DataReferences\\\": {}, \\\"Data\\\": {\\\"mnist_tf\\\": {\\\"DataLocation\\\": {\\\"Dataset\\\": null, \\\"DataPath\\\": null, \\\"Uri\\\": {\\\"Path\\\": \\\"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/data/mnist_tfrecords_data/versions/1\\\", \\\"IsFile\\\": false}, \\\"Type\\\": \\\"UriFolder\\\"}, \\\"Mechanism\\\": \\\"Mount\\\", \\\"EnvironmentVariableName\\\": \\\"AZURE_ML_INPUT_mnist_tf\\\", \\\"PathOnCompute\\\": null, \\\"Overwrite\\\": false, \\\"Options\\\": {\\\"IsEvalMode\\\": \\\"False\\\", \\\"ReadWrite\\\": \\\"False\\\", \\\"ForceFolder\\\": \\\"False\\\"}}}, \\\"InputAssets\\\": {\\\"mnist_tf\\\": {\\\"Asset\\\": {\\\"AssetId\\\": \\\"azureml://locations/eastus/workspaces/e3065a8e-03f5-431f-a3d9-976175f54379/data/mnist_tfrecords_data/versions/1\\\", \\\"Type\\\": \\\"UriFolder\\\"}, \\\"Mechanism\\\": \\\"Mount\\\", \\\"EnvironmentVariableName\\\": \\\"AZURE_ML_INPUT_mnist_tf\\\", \\\"PathOnCompute\\\": null, \\\"Overwrite\\\": false, \\\"Options\\\": {\\\"IsEvalMode\\\": \\\"False\\\", \\\"ReadWrite\\\": \\\"False\\\", \\\"ForceFolder\\\": \\\"False\\\"}}}, \\\"OutputData\\\": {}, \\\"Datacaches\\\": [], \\\"JobName\\\": null, \\\"MaxRunDurationSeconds\\\": null, \\\"NodeCount\\\": 1, \\\"InstanceTypes\\\": [], \\\"Priority\\\": null, \\\"CredentialPassthrough\\\": false, \\\"Identity\\\": null, \\\"Environment\\\": {\\\"Name\\\": \\\"test-remote-cpu-env-for-logging\\\", \\\"Version\\\": \\\"1\\\", \\\"AssetId\\\": \\\"azureml://locations/eastus/workspaces/e3065a8e-03f5-431f-a3d9-976175f54379/environments/test-remote-cpu-env-for-logging/versions/1\\\", \\\"Python\\\": {\\\"InterpreterPath\\\": null, \\\"UserManagedDependencies\\\": false, \\\"CondaDependencies\\\": {\\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"tensorflow-gpu==1.15\\\", \\\"mlflow\\\", \\\"azureml-mlflow\\\"]}], \\\"name\\\": \\\"project_environment\\\"}, \\\"BaseCondaEnvironment\\\": null}, \\\"EnvironmentVariables\\\": {}, \\\"Docker\\\": {\\\"BaseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\\\", \\\"Platform\\\": {\\\"Os\\\": \\\"Linux\\\", \\\"Architecture\\\": \\\"amd64\\\"}, \\\"BaseDockerfile\\\": null, \\\"BaseImageRegistry\\\": null}, \\\"Spark\\\": {\\\"Repositories\\\": [], \\\"Packages\\\": [], \\\"PrecachePackages\\\": true}, \\\"InferencingStackVersion\\\": null}, \\\"History\\\": {\\\"OutputCollection\\\": true, \\\"DirectoriesToWatch\\\": [\\\"logs\\\"], \\\"EnableMLflowTracking\\\": true}, \\\"Spark\\\": {\\\"Configuration\\\": {}}, \\\"ParallelTask\\\": {\\\"MaxRetriesPerWorker\\\": 0, \\\"WorkerCountPerNode\\\": 1, \\\"TerminalExitCodes\\\": null, \\\"Configuration\\\": {}}, \\\"BatchAi\\\": {\\\"NodeCount\\\": 0}, \\\"AmlCompute\\\": {\\\"Name\\\": null, \\\"VmSize\\\": null, \\\"RetainCluster\\\": false, \\\"ClusterMaxNodeCount\\\": null}, \\\"AISuperComputer\\\": {\\\"InstanceType\\\": \\\"D2\\\", \\\"FrameworkImage\\\": null, \\\"ImageVersion\\\": \\\"pytorch-1.7.0\\\", \\\"Location\\\": null, \\\"AISuperComputerStorageData\\\": null, \\\"Interactive\\\": false, \\\"ScalePolicy\\\": null, \\\"VirtualClusterArmId\\\": null, \\\"TensorboardLogDirectory\\\": null, \\\"SSHPublicKey\\\": null, \\\"SSHPublicKeys\\\": null, \\\"EnableAzmlInt\\\": true, \\\"Priority\\\": \\\"Medium\\\", \\\"SLATier\\\": \\\"Standard\\\", \\\"UserAlias\\\": null}, \\\"KubernetesCompute\\\": {\\\"InstanceType\\\": null}, \\\"Tensorflow\\\": {\\\"WorkerCount\\\": 0, \\\"ParameterServerCount\\\": 0}, \\\"Mpi\\\": {\\\"ProcessCountPerNode\\\": 0}, \\\"PyTorch\\\": {\\\"CommunicationBackend\\\": null, \\\"ProcessCount\\\": null}, \\\"Hdi\\\": {\\\"YarnDeployMode\\\": 0}, \\\"ContainerInstance\\\": {\\\"Region\\\": null, \\\"CpuCores\\\": 2.0, \\\"MemoryGb\\\": 3.5}, \\\"ExposedPorts\\\": null, \\\"Docker\\\": {\\\"UseDocker\\\": true, \\\"SharedVolumes\\\": null, \\\"ShmSize\\\": null, \\\"Arguments\\\": null}, \\\"Cmk8sCompute\\\": {\\\"Configuration\\\": {}}, \\\"CommandReturnCodeConfig\\\": {\\\"ReturnCode\\\": 0, \\\"SuccessfulReturnCodes\\\": []}, \\\"EnvironmentVariables\\\": {}, \\\"ApplicationEndpoints\\\": {}, \\\"Parameters\\\": []}, \\\"SnapshotId\\\": \\\"d61b3e31-da5b-4bde-a4d8-ed4be31b4ba9\\\", \\\"Snapshots\\\": [], \\\"SourceCodeDataReference\\\": null, \\\"ParentRunId\\\": null, \\\"DataContainerId\\\": null, \\\"RunType\\\": null, \\\"DisplayName\\\": \\\"hyperdrive_test\\\", \\\"EnvironmentAssetId\\\": null, \\\"Properties\\\": {}, \\\"Tags\\\": {}, \\\"AggregatedArtifactPath\\\": null}}\",\n",
      "    \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\", \\\"properties\\\": {}}\",\n",
      "    \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"training_accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\",\n",
      "    \"_aml_system_resume_child_runs\": \"null\"\n",
      "  },\n",
      "  \"trial\": {\n",
      "    \"code\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/codes/c8214493-5fd0-46cc-8a3f-05fe56c8c68c/versions/1\",\n",
      "    \"command\": \"python train_experiment.py --data_folder ${{inputs.mnist_tf}} --learning_rate ${{search_space.learning_rate}} --first_layer ${{search_space.first_layer}} --second_layer ${{search_space.second_layer}}\",\n",
      "    \"environment\": \"azureml:test-remote-cpu-env-for-logging:1\",\n",
      "    \"environment_variables\": {},\n",
      "    \"resources\": {\n",
      "      \"instance_count\": 1,\n",
      "      \"properties\": {}\n",
      "    }\n",
      "  },\n",
      "  \"type\": \"sweep\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file 07_hyperparam_job.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view logs and metrics in jobs on [Azure ML studio UI](https://ml.azure.com/).\n",
    "\n",
    "![AML Hyperdrive Metrics](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20220225_Hyperdrive_Metrics.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting compute hypertest01 \n",
      "...........Done.\n",
      "(0m 56s)\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute delete --name hypertest01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
