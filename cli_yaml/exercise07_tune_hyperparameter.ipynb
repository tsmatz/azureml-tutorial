{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise07 : Hyperparameter Tuning\n",
    "\n",
    "AML provides framework-independent hyperparameter tuning capability.    \n",
    "This capability monitors accuracy in AML logs.\n",
    "\n",
    "*back to [index](https://github.com/tsmatz/azureml-tutorial-tensorflow-v1/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable's Setting\n",
    "\n",
    "Replace below's branket's string and set the required variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resource_group = \"{AML-RESOURCE-GROUP-NAME}\"\n",
    "my_workspace = \"{AML-WORSPACE-NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your training code\n",
    "\n",
    "First, you must save your training code.    \n",
    "Here we should use the source code in \"[Exercise06 : Experimentation Logs and Outputs](./exercise06_experimentation.ipynb)\", which sends logs periodically into AML run history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ```scirpt``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save source code as ```./script/train_expriment.py```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script/train_experiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile script/train_experiment.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# Get run when running in remote\n",
    "if 'run' not in locals():\n",
    "    run = Run.get_context()\n",
    "\n",
    "FLAGS = None\n",
    "batch_size = 100\n",
    "\n",
    "#\n",
    "# define functions for Estimator\n",
    "#\n",
    "\n",
    "def _my_input_fn(filepath, num_epochs):\n",
    "    # image - 784 (=28 x 28) elements of grey-scaled integer value [0, 1]\n",
    "    # label - digit (0, 1, ..., 9)\n",
    "    data_queue = tf.train.string_input_producer(\n",
    "        [filepath],\n",
    "        num_epochs = num_epochs) # data is repeated and it raises OutOfRange when data is over\n",
    "    data_reader = tf.TFRecordReader()\n",
    "    _, serialized_exam = data_reader.read(data_queue)\n",
    "    data_exam = tf.parse_single_example(\n",
    "        serialized_exam,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    data_image = tf.decode_raw(data_exam['image_raw'], tf.uint8)\n",
    "    data_image.set_shape([784])\n",
    "    data_image = tf.cast(data_image, tf.float32) * (1. / 255)\n",
    "    data_label = tf.cast(data_exam['label'], tf.int32)\n",
    "    data_batch_image, data_batch_label = tf.train.batch(\n",
    "        [data_image, data_label],\n",
    "        batch_size=batch_size)\n",
    "    return {'inputs': data_batch_image}, data_batch_label\n",
    "\n",
    "def _get_input_fn(filepath, num_epochs):\n",
    "    return lambda: _my_input_fn(filepath, num_epochs)\n",
    "\n",
    "def _my_model_fn(features, labels, mode):\n",
    "    # with tf.device(...): # You can set device if using GPUs\n",
    "\n",
    "    # define network and inference\n",
    "    # (simple 2 fully connected hidden layer : 784->128->64->10)\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [784, FLAGS.first_layer],\n",
    "                stddev=1.0 / math.sqrt(float(784))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.first_layer]),\n",
    "            name='biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(features['inputs'], weights) + biases)\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.first_layer, FLAGS.second_layer],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.first_layer))),\n",
    "            name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([FLAGS.second_layer]),\n",
    "            name='biases')\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(\n",
    "            tf.truncated_normal(\n",
    "                [FLAGS.second_layer, 10],\n",
    "                stddev=1.0 / math.sqrt(float(FLAGS.second_layer))),\n",
    "        name='weights')\n",
    "        biases = tf.Variable(\n",
    "            tf.zeros([10]),\n",
    "            name='biases')\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    " \n",
    "    # compute evaluation matrix\n",
    "    predicted_indices = tf.argmax(input=logits, axis=1)\n",
    "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
    "        label_indices = tf.cast(labels, tf.int32)\n",
    "        accuracy = tf.metrics.accuracy(label_indices, predicted_indices)\n",
    "        tf.summary.scalar('accuracy', accuracy[1]) # output to TensorBoard \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels,\n",
    "            logits=logits)\n",
    " \n",
    "    # define operations\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        #global_step = tf.train.create_global_step()\n",
    "        #global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        global_step = tf.train.get_or_create_global_step()        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=global_step)\n",
    "        # Ask for accuracy and loss in each steps\n",
    "        class _CustomLoggingHook(tf.train.SessionRunHook):\n",
    "            def begin(self):\n",
    "                self.training_accuracy = []\n",
    "                self.training_loss = []\n",
    "            def before_run(self, run_context):\n",
    "                return tf.train.SessionRunArgs([accuracy[1], loss, global_step])\n",
    "            def after_run(self, run_context, run_values):\n",
    "                result_accuracy, result_loss, result_step = run_values.results\n",
    "                if result_step % 10 == 0 :\n",
    "                    self.training_accuracy.append(result_accuracy)\n",
    "                    self.training_loss.append(result_loss)\n",
    "                if result_step % 100 == 0 : # save logs in each 100 steps\n",
    "                    run.log_list('training_accuracy', self.training_accuracy)\n",
    "                    run.log_list('training_loss', self.training_loss)\n",
    "                    self.training_accuracy = []\n",
    "                    self.training_loss = []\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            training_chief_hooks=[_CustomLoggingHook()],\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metric_ops)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        probabilities = tf.nn.softmax(logits, name='softmax_tensor')\n",
    "        predictions = {\n",
    "            'classes': predicted_indices,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "        export_outputs = {\n",
    "            'prediction': tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            predictions=predictions,\n",
    "            export_outputs=export_outputs)\n",
    "\n",
    "def _my_serving_input_fn():\n",
    "    inputs = {'inputs': tf.placeholder(tf.float32, [None, 784])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "#\n",
    "# Main\n",
    "#\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--data_folder',\n",
    "    type=str,\n",
    "    default='./data',\n",
    "    help='Folder path for input data')\n",
    "parser.add_argument(\n",
    "    '--chkpoint_folder',\n",
    "    type=str,\n",
    "    default='./logs',  # AML experiments logs folder\n",
    "    help='Folder path for checkpoint files')\n",
    "parser.add_argument(\n",
    "    '--model_folder',\n",
    "    type=str,\n",
    "    default='./outputs',  # AML experiments outputs folder\n",
    "    help='Folder path for model output')\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default='0.07',\n",
    "    help='Learning Rate')\n",
    "parser.add_argument(\n",
    "    '--first_layer',\n",
    "    type=int,\n",
    "    default='128',\n",
    "    help='Neuron number for the first hidden layer')\n",
    "parser.add_argument(\n",
    "    '--second_layer',\n",
    "    type=int,\n",
    "    default='64',\n",
    "    help='Neuron number for the second hidden layer')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "# clean checkpoint and model folder if exists\n",
    "if os.path.exists(FLAGS.chkpoint_folder) :\n",
    "    for file_name in os.listdir(FLAGS.chkpoint_folder):\n",
    "        file_path = os.path.join(FLAGS.chkpoint_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "if os.path.exists(FLAGS.model_folder) :\n",
    "    for file_name in os.listdir(FLAGS.model_folder):\n",
    "        file_path = os.path.join(FLAGS.model_folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "\n",
    "# read TF_CONFIG\n",
    "run_config = tf.estimator.RunConfig()\n",
    "\n",
    "# create Estimator\n",
    "mnist_fullyconnected_classifier = tf.estimator.Estimator(\n",
    "    model_fn=_my_model_fn,\n",
    "    model_dir=FLAGS.chkpoint_folder,\n",
    "    config=run_config)\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'train.tfrecords'), 2),\n",
    "    max_steps=60000 * 2 / batch_size)\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=_get_input_fn(os.path.join(FLAGS.data_folder, 'test.tfrecords'), 1),\n",
    "    steps=10000 * 1 / batch_size,\n",
    "    start_delay_secs=0)\n",
    "\n",
    "# run !\n",
    "eval_res = tf.estimator.train_and_evaluate(\n",
    "    mnist_fullyconnected_classifier,\n",
    "    train_spec,\n",
    "    eval_spec\n",
    ")\n",
    "\n",
    "# save model and variables\n",
    "model_dir = mnist_fullyconnected_classifier.export_savedmodel(\n",
    "    export_dir_base = FLAGS.model_folder,\n",
    "    serving_input_receiver_fn = _my_serving_input_fn)\n",
    "print('current working directory is ', os.getcwd())\n",
    "print('model is saved ', model_dir)\n",
    "\n",
    "# send logs to AML\n",
    "run.log('learning_rate', FLAGS.learning_rate)\n",
    "run.log('1st_layer', FLAGS.first_layer)\n",
    "run.log('2nd_layer', FLAGS.second_layer)\n",
    "run.log('final_accuracy', eval_res[0]['accuracy'])\n",
    "run.log('final_loss', eval_res[0]['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AML compute\n",
    "\n",
    "Create AML compute pool for computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml compute' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "{\n",
      "  \"id\": \"/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/computes/hypertest01\",\n",
      "  \"idle_time_before_scale_down\": 120,\n",
      "  \"location\": \"eastus\",\n",
      "  \"max_instances\": 4,\n",
      "  \"min_instances\": 0,\n",
      "  \"name\": \"hypertest01\",\n",
      "  \"network_settings\": {},\n",
      "  \"provisioning_state\": \"Succeeded\",\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"size\": \"STANDARD_D2_V2\",\n",
      "  \"ssh_public_access_enabled\": true,\n",
      "  \"tier\": \"dedicated\",\n",
      "  \"type\": \"amlcompute\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute create --name hypertest01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 4 \\\n",
    "  --size Standard_D2_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a job with hyper-parameter's search\n",
    "\n",
    "Now submit a job, in which multiple trainings will run depending on different hyper-parameters.<br>\n",
    "In this example, we monitor training accuracy depending on 3 arguments - ```--learning_rate```, ```--first_layer```, and ```--second_layer```. Each arguments can have 3 different values (and then total 27 trials can be run), but here I set 20 trials to run, in which the values of arguments are randomly picked up.\n",
    "<br>These trials will be parralelized on above 4 node to speed up.\n",
    "\n",
    "For ```sampling_algorithm```, you can use ```grid```, ```random```, and ```bayesian```.<br>\n",
    "You can also specify an early termnination policy (```early_termination```), in which the training will terminate if the primary metric falls outside of some threshold.\n",
    "\n",
    "> Note : In this example, I also use the registered dataset  (train.tfrecords, test.tfrecords) named ```mnist_tfrecords_dataset``` to mount in your compute target. Run \"[Exercise02 : Prepare Data](./exercise02_prepare_data.ipynb)\" for dataset preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 07_hyperparam_job.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile 07_hyperparam_job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/sweepJob.schema.json\n",
    "type: sweep\n",
    "trial:\n",
    "  code: \n",
    "    local_path: script\n",
    "  command: >-\n",
    "    python train_experiment.py\n",
    "    --data_folder ${{inputs.mnist_tf}}\n",
    "    --learning_rate ${{search_space.learning_rate}}\n",
    "    --first_layer ${{search_space.first_layer}}\n",
    "    --second_layer ${{search_space.second_layer}}\n",
    "  environment: azureml:AzureML-TensorFlow-1.13-CPU:30\n",
    "inputs:\n",
    "  mnist_tf: \n",
    "    dataset: azureml:mnist_tfrecords_dataset:1\n",
    "compute: azureml:hypertest01\n",
    "sampling_algorithm: random\n",
    "search_space:\n",
    "  learning_rate:\n",
    "    type: choice\n",
    "    values: [0.01, 0.05, 0.9]\n",
    "  first_layer:\n",
    "    type: choice\n",
    "    values: [100, 125, 150]\n",
    "  second_layer:\n",
    "    type: choice\n",
    "    values: [30, 60, 90]\n",
    "objective:\n",
    "  goal: maximize\n",
    "  primary_metric: training_accuracy\n",
    "limits:\n",
    "  max_total_trials: 20\n",
    "  max_concurrent_trials: 4\n",
    "display_name: hyperdrive_test\n",
    "experiment_name: hyperdrive_test\n",
    "description: This is example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml job' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "\u001b[32mUploading script (0.02 MBs): 100%|████| 23198/23198 [00:00<00:00, 839809.29it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "{\n",
      "  \"compute\": \"azureml:hypertest01\",\n",
      "  \"creation_context\": {\n",
      "    \"created_at\": \"2022-02-28T00:58:51.904469+00:00\",\n",
      "    \"created_by\": \"Tsuyoshi Matsuzaki\",\n",
      "    \"created_by_type\": \"User\"\n",
      "  },\n",
      "  \"description\": \"This is example\",\n",
      "  \"display_name\": \"hyperdrive_test\",\n",
      "  \"experiment_name\": \"hyperdrive_test\",\n",
      "  \"id\": \"azureml:/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourceGroups/AML-rg/providers/Microsoft.MachineLearningServices/workspaces/ws01/jobs/abae7524-ff7c-42dc-802c-a23eee7c44db\",\n",
      "  \"inputs\": {\n",
      "    \"mnist_tf\": {\n",
      "      \"dataset\": \"azureml:mnist_tfrecords_dataset:1\",\n",
      "      \"mode\": \"ro_mount\"\n",
      "    }\n",
      "  },\n",
      "  \"limits\": {\n",
      "    \"max_concurrent_trials\": 4,\n",
      "    \"max_total_trials\": 20,\n",
      "    \"timeout\": 5184000\n",
      "  },\n",
      "  \"name\": \"abae7524-ff7c-42dc-802c-a23eee7c44db\",\n",
      "  \"objective\": {\n",
      "    \"goal\": \"maximize\",\n",
      "    \"primary_metric\": \"training_accuracy\"\n",
      "  },\n",
      "  \"outputs\": {\n",
      "    \"default\": {\n",
      "      \"folder\": \"azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.abae7524-ff7c-42dc-802c-a23eee7c44db\",\n",
      "      \"mode\": \"rw_mount\"\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"ContentSnapshotId\": \"25430116-ff20-4135-a90a-d65aad8514f9\",\n",
      "    \"azureml.runsource\": \"hyperdrive\",\n",
      "    \"platform\": \"AML\",\n",
      "    \"primary_metric_config\": \"{\\\"name\\\": \\\"training_accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\",\n",
      "    \"resume_from\": \"null\",\n",
      "    \"runTemplate\": \"HyperDrive\",\n",
      "    \"user_agent\": \"managementfrontend/4ac8a010185e79117fcca2d80ea4283b9048f741\"\n",
      "  },\n",
      "  \"resourceGroup\": \"AML-rg\",\n",
      "  \"sampling_algorithm\": \"random\",\n",
      "  \"search_space\": {\n",
      "    \"first_layer\": {\n",
      "      \"type\": \"choice\",\n",
      "      \"values\": [\n",
      "        100,\n",
      "        125,\n",
      "        150\n",
      "      ]\n",
      "    },\n",
      "    \"learning_rate\": {\n",
      "      \"type\": \"choice\",\n",
      "      \"values\": [\n",
      "        0.01,\n",
      "        0.05,\n",
      "        0.9\n",
      "      ]\n",
      "    },\n",
      "    \"second_layer\": {\n",
      "      \"type\": \"choice\",\n",
      "      \"values\": [\n",
      "        30,\n",
      "        60,\n",
      "        90\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"services\": {\n",
      "    \"Studio\": {\n",
      "      \"endpoint\": \"https://ml.azure.com/runs/abae7524-ff7c-42dc-802c-a23eee7c44db?wsid=/subscriptions/b3ae1c15-4fef-4362-8c3a-5d804cdeb18d/resourcegroups/AML-rg/workspaces/ws01&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\",\n",
      "      \"job_service_type\": \"Studio\"\n",
      "    }\n",
      "  },\n",
      "  \"status\": \"Running\",\n",
      "  \"tags\": {\n",
      "    \"_aml_system_all_jobs_generated\": \"false\",\n",
      "    \"_aml_system_cancellation_requested\": \"false\",\n",
      "    \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"properties\\\": {}, \\\"parameter_space\\\": {\\\"learning_rate\\\": [\\\"choice\\\", [[0.01, 0.05, 0.9]]], \\\"first_layer\\\": [\\\"choice\\\", [[100, 125, 150]]], \\\"second_layer\\\": [\\\"choice\\\", [[30, 60, 90]]]}}\",\n",
      "    \"_aml_system_max_concurrent_jobs\": \"4\",\n",
      "    \"_aml_system_max_duration_minutes\": \"86400\",\n",
      "    \"_aml_system_max_total_jobs\": \"20\",\n",
      "    \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://eastus.api.azureml.ms\\\", \\\"SubscriptionId\\\": \\\"b3ae1c15-4fef-4362-8c3a-5d804cdeb18d\\\", \\\"ResourceGroupName\\\": \\\"AML-rg\\\", \\\"WorkspaceName\\\": \\\"ws01\\\", \\\"ExperimentName\\\": \\\"hyperdrive_test\\\", \\\"Definition\\\": {\\\"Configuration\\\": null, \\\"Attribution\\\": null, \\\"TelemetryValues\\\": null, \\\"Overrides\\\": {\\\"Script\\\": null, \\\"Command\\\": \\\"python train_experiment.py --data_folder ${{inputs.mnist_tf}} --learning_rate ${{search_space.learning_rate}} --first_layer ${{search_space.first_layer}} --second_layer ${{search_space.second_layer}}\\\", \\\"UseAbsolutePath\\\": true, \\\"Arguments\\\": [], \\\"SourceDirectoryDataStore\\\": null, \\\"Framework\\\": 0, \\\"Target\\\": \\\"hypertest01\\\", \\\"DataReferences\\\": {}, \\\"Data\\\": {\\\"mnist_tf\\\": {\\\"DataLocation\\\": {\\\"Dataset\\\": {\\\"Id\\\": \\\"441e9b52-c4eb-4c32-bca3-10bacbe40f57\\\", \\\"Name\\\": null, \\\"Version\\\": null}, \\\"DataPath\\\": null, \\\"Uri\\\": null}, \\\"Mechanism\\\": \\\"Mount\\\", \\\"EnvironmentVariableName\\\": \\\"AZURE_ML_INPUT_mnist_tf\\\", \\\"PathOnCompute\\\": null, \\\"Overwrite\\\": false, \\\"Options\\\": {\\\"ReadWrite\\\": \\\"False\\\", \\\"ForceFolder\\\": \\\"True\\\"}}}, \\\"OutputData\\\": {}, \\\"Datacaches\\\": [], \\\"JobName\\\": null, \\\"MaxRunDurationSeconds\\\": null, \\\"NodeCount\\\": 1, \\\"InstanceTypes\\\": [], \\\"Priority\\\": null, \\\"CredentialPassthrough\\\": false, \\\"Identity\\\": null, \\\"Environment\\\": {\\\"Name\\\": \\\"AzureML-TensorFlow-1.13-CPU\\\", \\\"Version\\\": \\\"30\\\", \\\"Python\\\": {\\\"InterpreterPath\\\": \\\"python\\\", \\\"UserManagedDependencies\\\": false, \\\"CondaDependencies\\\": {\\\"channels\\\": [\\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-core==1.8.0.post1\\\", \\\"azureml-defaults==1.8.0\\\", \\\"azureml-telemetry==1.8.0\\\", \\\"azureml-train-restclients-hyperdrive==1.8.0\\\", \\\"azureml-train-core==1.8.0\\\", \\\"tensorflow==1.13.1\\\", \\\"horovod==0.16.1\\\"]}], \\\"name\\\": \\\"azureml_78a59f478ac9af9b0fabcc8ecac4b312\\\"}, \\\"BaseCondaEnvironment\\\": null}, \\\"EnvironmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"Docker\\\": {\\\"BaseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"Platform\\\": {\\\"Os\\\": \\\"Linux\\\", \\\"Architecture\\\": \\\"amd64\\\"}, \\\"BaseDockerfile\\\": null, \\\"BaseImageRegistry\\\": {\\\"Address\\\": null, \\\"Username\\\": null, \\\"Password\\\": null}, \\\"Enabled\\\": false, \\\"Arguments\\\": []}, \\\"Spark\\\": {\\\"Repositories\\\": [], \\\"Packages\\\": [], \\\"PrecachePackages\\\": true}, \\\"InferencingStackVersion\\\": null}, \\\"History\\\": {\\\"OutputCollection\\\": true, \\\"DirectoriesToWatch\\\": [\\\"logs\\\"], \\\"EnableMLflowTracking\\\": true}, \\\"Spark\\\": {\\\"Configuration\\\": {}}, \\\"ParallelTask\\\": {\\\"MaxRetriesPerWorker\\\": 0, \\\"WorkerCountPerNode\\\": 1, \\\"TerminalExitCodes\\\": null, \\\"Configuration\\\": {}}, \\\"BatchAi\\\": {\\\"NodeCount\\\": 0}, \\\"AmlCompute\\\": {\\\"Name\\\": null, \\\"VmSize\\\": null, \\\"RetainCluster\\\": false, \\\"ClusterMaxNodeCount\\\": null}, \\\"AISuperComputer\\\": {\\\"InstanceType\\\": \\\"D2\\\", \\\"FrameworkImage\\\": null, \\\"ImageVersion\\\": \\\"pytorch-1.7.0\\\", \\\"Location\\\": null, \\\"AISuperComputerStorageData\\\": null, \\\"Interactive\\\": false, \\\"ScalePolicy\\\": null, \\\"VirtualClusterArmId\\\": null, \\\"TensorboardLogDirectory\\\": null, \\\"SSHPublicKey\\\": null, \\\"SSHPublicKeys\\\": null, \\\"EnableAzmlInt\\\": true, \\\"Priority\\\": \\\"Medium\\\", \\\"SLATier\\\": \\\"Standard\\\", \\\"UserAlias\\\": null}, \\\"KubernetesCompute\\\": {\\\"InstanceType\\\": null}, \\\"Tensorflow\\\": {\\\"WorkerCount\\\": 0, \\\"ParameterServerCount\\\": 0}, \\\"Mpi\\\": {\\\"ProcessCountPerNode\\\": 0}, \\\"PyTorch\\\": {\\\"CommunicationBackend\\\": null, \\\"ProcessCount\\\": null}, \\\"Hdi\\\": {\\\"YarnDeployMode\\\": 0}, \\\"ContainerInstance\\\": {\\\"Region\\\": null, \\\"CpuCores\\\": 2.0, \\\"MemoryGb\\\": 3.5}, \\\"ExposedPorts\\\": null, \\\"Docker\\\": {\\\"UseDocker\\\": true, \\\"SharedVolumes\\\": null, \\\"ShmSize\\\": null, \\\"Arguments\\\": null}, \\\"Cmk8sCompute\\\": {\\\"Configuration\\\": {}}, \\\"CommandReturnCodeConfig\\\": {\\\"ReturnCode\\\": 0, \\\"SuccessfulReturnCodes\\\": []}, \\\"EnvironmentVariables\\\": {}, \\\"ApplicationEndpoints\\\": {}, \\\"Parameters\\\": []}, \\\"SnapshotId\\\": \\\"25430116-ff20-4135-a90a-d65aad8514f9\\\", \\\"Snapshots\\\": [], \\\"SourceCodeDataReference\\\": null, \\\"ParentRunId\\\": null, \\\"DataContainerId\\\": null, \\\"RunType\\\": null, \\\"DisplayName\\\": \\\"hyperdrive_test\\\", \\\"Properties\\\": {}, \\\"Tags\\\": {}, \\\"AggregatedArtifactPath\\\": null}}\",\n",
      "    \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\", \\\"properties\\\": {}}\",\n",
      "    \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"training_accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\",\n",
      "    \"_aml_system_resume_child_runs\": \"null\"\n",
      "  },\n",
      "  \"trial\": {\n",
      "    \"code\": \"azureml:d06b9437-82ea-4014-a50f-a2d83df699d4:1\",\n",
      "    \"command\": \"python train_experiment.py --data_folder ${{inputs.mnist_tf}} --learning_rate ${{search_space.learning_rate}} --first_layer ${{search_space.first_layer}} --second_layer ${{search_space.second_layer}}\",\n",
      "    \"environment\": \"azureml:AzureML-TensorFlow-1.13-CPU:30\",\n",
      "    \"environment_variables\": {},\n",
      "    \"resources\": {\n",
      "      \"instance_count\": 1,\n",
      "      \"properties\": {}\n",
      "    }\n",
      "  },\n",
      "  \"type\": \"sweep\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml job create --file 07_hyperparam_job.yml \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view logs and metrics in Experiments on [Azure ML studio UI](https://ml.azure.com/).\n",
    "\n",
    "![AML Hyperdrive Metrics](https://tsmatz.github.io/images/github/azure-ml-tensorflow-complete-sample/20220225_Hyperdrive_Metrics.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove AML compute\n",
    "\n",
    "**You don't need to remove your AML compute** for saving money, because the nodes will be automatically terminated, when it's inactive.<br>\n",
    "But if you want to clean up, please run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCommand group 'ml compute' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\u001b[0m\n",
      "Deleting compute hypertest01 \n",
      ".......Done.\n",
      "(0m 37s)\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!az ml compute delete --name hypertest01 \\\n",
    "  --resource-group $my_resource_group \\\n",
    "  --workspace-name $my_workspace \\\n",
    "  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
